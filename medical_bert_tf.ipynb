{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical_bert_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "v1YRVdjyrNbT",
        "exz-Kb1SP_W_",
        "Y_2crOsGQFyc",
        "AW1Mxf8zRupw",
        "ermBRSEwFryl",
        "X3yfkjoTW-pI",
        "9_Bd-ENfaRef",
        "ZVZfk8-Abj2b",
        "i2pMn0fDiXSX",
        "ESLDR_wftqr1"
      ],
      "toc_visible": true,
      "mount_file_id": "1OxVYtR9_dNhI4HYDJDfjSQnpTN8RF8sb",
      "authorship_tag": "ABX9TyMggATsadH4g9BJAj4y/FPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da5444aa86194ae68764ae89fa114b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3653f1ea23f145a099dc15677e7f7a38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d64fe5a74df944559d2a6c51092dbfd0",
              "IPY_MODEL_2680ec75590c41b6899d6f4936fff83b",
              "IPY_MODEL_e3250ab924024f088708cb373bc50620"
            ]
          }
        },
        "3653f1ea23f145a099dc15677e7f7a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d64fe5a74df944559d2a6c51092dbfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_423added286e41ae9363049c1819ce9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e480d899a92642aa9f89d34c6b65b8f2"
          }
        },
        "2680ec75590c41b6899d6f4936fff83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_406a68a9513a4361a64cb8111485442f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1110,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1110,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a273af078c894fa09ec41c6809042008"
          }
        },
        "e3250ab924024f088708cb373bc50620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e1f6a4d95994309a4e0c8751ae13c1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08k/1.08k [00:00&lt;00:00, 26.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4a7049ff1b544da91a78e926c2bc838"
          }
        },
        "423added286e41ae9363049c1819ce9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e480d899a92642aa9f89d34c6b65b8f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "406a68a9513a4361a64cb8111485442f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a273af078c894fa09ec41c6809042008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e1f6a4d95994309a4e0c8751ae13c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4a7049ff1b544da91a78e926c2bc838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a4865a8ddbb46e9849fc2ee4038ee19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e4347f13a9d4237bc0b7350ed8c8f42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3110a80401554b67abb9378bc98514aa",
              "IPY_MODEL_1ec7f6f5a28c4ea5864bf29a73a94025",
              "IPY_MODEL_8c607859e4c24b53a3414b778b6af9b7"
            ]
          }
        },
        "8e4347f13a9d4237bc0b7350ed8c8f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3110a80401554b67abb9378bc98514aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9fedbcac3ce42c891df7fc03c3803e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5ee89f3cd4c485da8ee64931c567c53"
          }
        },
        "1ec7f6f5a28c4ea5864bf29a73a94025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b3241ff7be145a7aa08fb0ac26fbfd9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435783451,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435783451,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dd20968a0ef4a0aaa275cdea3efb3fd"
          }
        },
        "8c607859e4c24b53a3414b778b6af9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bfc8094a05a4af0ab684f4a1fbc2a2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 416M/416M [00:13&lt;00:00, 33.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_835003a9c36f473e81c363591348a379"
          }
        },
        "b9fedbcac3ce42c891df7fc03c3803e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5ee89f3cd4c485da8ee64931c567c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b3241ff7be145a7aa08fb0ac26fbfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dd20968a0ef4a0aaa275cdea3efb3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bfc8094a05a4af0ab684f4a1fbc2a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "835003a9c36f473e81c363591348a379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dd13d4edca94bf3a5862fc4af4198ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55e5b83850b14160a542a9aedb418ece",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b50d3364b66a4051b86042fe18103775",
              "IPY_MODEL_4d3fbc2c65ee4d2e9b11b2c72c4fef91",
              "IPY_MODEL_bc14e38fad904013a563949e3a667830"
            ]
          }
        },
        "55e5b83850b14160a542a9aedb418ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b50d3364b66a4051b86042fe18103775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6212a47c4a749bc97ffafa1af5777e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20e61f627f6a4f06944c18be6541497c"
          }
        },
        "4d3fbc2c65ee4d2e9b11b2c72c4fef91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41383973c98946ac8db3108e96658ee5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc6aee2eacac4b279e3880bc93130c36"
          }
        },
        "bc14e38fad904013a563949e3a667830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f997e0a13444f18ab800ede853e2431",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 208k/208k [00:00&lt;00:00, 611kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be177624ef35480c86c69159f500079b"
          }
        },
        "c6212a47c4a749bc97ffafa1af5777e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20e61f627f6a4f06944c18be6541497c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41383973c98946ac8db3108e96658ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc6aee2eacac4b279e3880bc93130c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f997e0a13444f18ab800ede853e2431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be177624ef35480c86c69159f500079b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyanakai/medical_paper_classification/blob/main/medical_bert_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmYQsaQ212VL"
      },
      "source": [
        "<h1>医学論文の自動仕分けチャレンジ 訓練</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB9bBdbU17Wm"
      },
      "source": [
        "# １. はじめに\n",
        "\n",
        "本ノートブックでは、SIGNATE上で開催された文章分類コンペティション[医学論文の自動仕分けチャレンジ](https://signate.jp/competitions/471)のタスクに基づいて、BERTモデルを訓練します。<br>\n",
        "データは[medical_EDA.ipynb](https://github.com/Tyanakai/medical_paper_classification/blob/main/medical_EDA.ipynb)において前処理し保存したファイル(`p_train.csv`,`p_test.csv`)を使用します。<br>\n",
        "使用するモデルは、以下の通りです。\n",
        "<br>\n",
        "\n",
        "*   [BioELECTRA](https://github.com/kamalkraj/BioELECTRA)\n",
        "*   [SapBERT](https://huggingface.co/cambridgeltl/SapBERT-from-PubMedBERT-fulltext)\n",
        "*   [PubMedBERT](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext)\n",
        "*   [BioBERT](https://huggingface.co/dmis-lab/biobert-base-cased-v1.2)\n",
        "\n",
        "尚、colabratory上で、ランタイムのタイプをTPUに設定した状態での実行を想定しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFGzxVit4NKR"
      },
      "source": [
        "# ２. 事前に完了していること\n",
        "\n",
        "- [medical_EDA.ipynb](https://github.com/Tyanakai/medical_paper_classification/blob/main/medical_EDA.ipynb)を実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5bLdmt7G5xD"
      },
      "source": [
        "# ３. 環境準備\n",
        "訓練環境を構築します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1YRVdjyrNbT"
      },
      "source": [
        "## 3.1 ライブラリ準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHvKphT8BMKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c339e8f7-9d66-48f6-ef8c-0795057ad55f"
      },
      "source": [
        "! pip install -q transformers\n",
        "! pip install -q tensorflow-addons\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.optimize import minimize\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "import transformers\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 27.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exz-Kb1SP_W_"
      },
      "source": [
        "## 3.2 TPU設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPdMBltfWeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8afac2-0ad3-41ca-e916-c39281978ef4"
      },
      "source": [
        "try:\n",
        "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', TPU.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    TPU = None\n",
        "    print('INFO: Not connected to a TPU runtime')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.103.118.194:8470']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B59L5n9DQjEc"
      },
      "source": [
        "## 3.3 Google Driveマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g26P5nFOQrRl"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajhXgI0Celo0"
      },
      "source": [
        "## 3.4 ハイパーパラメータ設定\n",
        "ハイパーパラメータを設定します。\n",
        "\n",
        "|パラメータ名|説明|\n",
        "|:-|:-|\n",
        "|model| Hugging Face内のパス。ローカルフォルダやファイルの命名にも用いる|\n",
        "|from_pt|tf_model.h5が公開されていない場合、Trueとする|\n",
        "|encode_type|encoderの出力形式。cf.) 4.1 model定義|\n",
        "|-|-|\n",
        "|max_length|入力する最大token数|\n",
        "|opt|使用するscipy.optimizeのアルゴリズム|\n",
        "|patience|EarlyStoppingのパラメータ。訓練早期終了を延期するepoch数|\n",
        "|check_monitor|ModelCheckpointのパラメータ。保存するmodelの選定指標|\n",
        "|check_mode|check_monitorでval_aucを選択した場合\"max\"でないと正常に機能しない\n",
        "|-|-|\n",
        "|loss_fn|損失関数。\"bce\" : binary crossentropy, \"focal\" : focal binary crossentropy| \n",
        "|loss_weight|loss_fnをweighted_bceにした場合、負例、正例にそれぞれ乗算する重みを設定する|\n",
        "|class_weight|model.fit()時にclass別に重みを乗算する。loss_weightと同時に使用しない。cf.) 6.4 class weight|\n",
        "|-|-|\n",
        "|target_col|判定するラベル列|\n",
        "|text_col|入力として用いる列|\n",
        "|-|-|\n",
        "|temp_thre|仮の閾値|\n",
        "|-|-|\n",
        "|time_jp|日本標準時。ファイル名を区別するために使用|\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBKkHi54SQSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ae56fea-0f40-4d77-fdba-245076447026"
      },
      "source": [
        "class Config:\n",
        "    model = \"dmis-lab/biobert-base-cased-v1.2\" #@param\n",
        "    from_pt = True #@param {\"type\":\"boolean\"}\n",
        "    encode_type = \"cls_cat\" #@param {\"type\",\"string\"} [\"cls\",\"cls_cat\",\"pooler\",\"logits\", \"last_hidden_state_cnn\", \"last_hidden_state_lstm\"]\n",
        "\n",
        "    max_length = 512 #@param {\"type\":\"integer\"}\n",
        "    lr = 0.00002\n",
        "    weight_decay = 1e-5\n",
        "    opt = \"minimize\"  #@param {\"type\":\"string\"} [\"minimize_scalar\",\"minimize\"]\n",
        "    n_fold = 5 #@param\n",
        "    epochs = 15 #@param {\"type\":\"slider\"}\n",
        "    patience = 4 #@param\n",
        "    check_monitor = \"val_fbeta_score\" #@param {\"type\":\"string\"} [\"val_loss\",\"val_fbeta_score\",\"val_auc\"]\n",
        "    check_mode = \"max\" #@param {\"type\":\"string\"} [\"auto\", \"max\"]\n",
        "    \n",
        "    train_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
        "    valid_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
        "    test_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
        "    steps_per_epochs = None #(27145 * (n_fold - 1) / n_fold) // train_batch_size\n",
        "    train_file = \"p_train.csv\" #@param\n",
        "    test_file = \"p_test.csv\" #@param\n",
        "    target_col = \"judgement\"\n",
        "    text_col = \"text\"\n",
        "    seeds = [21]\n",
        "\n",
        "    loss_fn = \"bce\" #@param {\"type\":\"string\"} [\"bce\", \"weighted_bce\", \"focal\"]\n",
        "    loss_weight = [1, 50] #@param\n",
        "    class_weight = \"balanced\" #@param {\"type\":\"raw\"}     \n",
        "    label_smoothing = 0 #@param\n",
        "    \n",
        "    submit = True #@param {\"type\":\"boolean\"}\n",
        "    debug = True  #@param {\"type\":\"boolean\"}\n",
        "    temp_thre = 0.1 #@param\n",
        "\n",
        "if Config.debug:\n",
        "    Config.epochs = 2\n",
        "    Config.n_fold = 2\n",
        "\n",
        "time_jp = (datetime.datetime.now() + \n",
        "           datetime.timedelta(hours=9)).strftime('%Y%m%d_%H%M')\n",
        "# time_jp = '20210926_1749' #@param\n",
        "time_jp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'20211103_1003'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_2crOsGQFyc"
      },
      "source": [
        "## 3.5 pathの設定\n",
        "pathを設定し必要なフォルダを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O9-YHdofe6H"
      },
      "source": [
        "DRIVE = \"/content/drive/MyDrive/signate/medical_paper\"\n",
        "INPUT = os.path.join(DRIVE, \"input\")\n",
        "OUTPUT = os.path.join(DRIVE, \"output\")\n",
        "LOG = os.path.join(OUTPUT, f\"{Config.model.replace('/','-')}_tf\")\n",
        "MODEL = os.path.join(DRIVE, \"model\", f\"{Config.model.replace('/','-')}_tf\")\n",
        "SUBMIT = os.path.join(DRIVE, \"submit\") # 提出ファイルを保存するフォルダ\n",
        "PROB = os.path.join(DRIVE, \"prob\") # 予測確率値(probability)を保存するフォルダ\n",
        "\n",
        "for folder in [DRIVE, INPUT, OUTPUT, LOG, MODEL, SUBMIT, PROB]:\n",
        "    os.makedirs(folder, exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW1Mxf8zRupw"
      },
      "source": [
        "## 3.6 loggingの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nQXayCa7XaO"
      },
      "source": [
        "class Logger:\n",
        "    \"\"\"\n",
        "    log を残す用のクラス\n",
        "    path : logを保存するフォルダ \n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        self.general_logger = logging.getLogger(__name__)\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        file_general_handler = logging.FileHandler(os.path.join(path, f'Experiment{time_jp}.log'))\n",
        "        if len(self.general_logger.handlers) == 0:\n",
        "            # self.general_logger.addHandler(stream_handler)\n",
        "            self.general_logger.addHandler(file_general_handler)\n",
        "            self.general_logger.setLevel(logging.INFO)\n",
        "\n",
        "    def info(self, message):\n",
        "        # 時刻とmessageを記録\n",
        "        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n",
        "\n",
        "    @staticmethod\n",
        "    def now_string():\n",
        "        # 時刻を取得\n",
        "        cur_time = datetime.datetime.now() + datetime.timedelta(hours=9)\n",
        "        return cur_time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "logger = Logger(LOG)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWzk922D68L"
      },
      "source": [
        "# ４. model, tokenizer準備\n",
        "訓練するmodelやtokenizerを取得する関数を定義します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC2-ygoEFkBk"
      },
      "source": [
        "## 4.1 model定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqEOf5pnSx18"
      },
      "source": [
        "def build_encoder():\n",
        "    \"\"\"\n",
        "    encoderの出力形式(Config.encode_type)に従って\n",
        "    設定を変化させたencoderを返します。\n",
        "    \"\"\"\n",
        "    if Config.encode_type == \"logits\":\n",
        "        encoder = (\n",
        "            transformers\n",
        "            .TFAutoModelForSequenceClassification\n",
        "            .from_pretrained(Config.model, num_labels=1, from_pt=Config.from_pt)\n",
        "        )\n",
        "\n",
        "    elif Config.encode_type == \"cls_cat\":\n",
        "        # 最終層以外のhidden_statesを出力する為のconfig\n",
        "        config = (\n",
        "            transformers.\n",
        "            AutoConfig.\n",
        "            from_pretrained(Config.model, output_hidden_states=True)\n",
        "        )\n",
        "\n",
        "        encoder = (\n",
        "            transformers\n",
        "            .TFAutoModel\n",
        "            .from_pretrained(Config.model, config=config, from_pt=Config.from_pt)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        encoder = (\n",
        "            transformers\n",
        "            .TFAutoModel\n",
        "            .from_pretrained(Config.model, from_pt=Config.from_pt)\n",
        "        )\n",
        "\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def neural_networks(x):\n",
        "    \"\"\"\n",
        "    encoderの出力形式(Config.encode_type)に従って\n",
        "    encoder以降の構造を定義します。\n",
        "    \"\"\"\n",
        "\n",
        "    if Config.encode_type == \"cls\":\n",
        "        # cls tokenを使用\n",
        "        x = x[0][:, 0, :]\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    elif Config.encode_type == \"cls_cat\":\n",
        "        # encoderの最終四層分のcls tokenを連結\n",
        "        x = tf.concat([x[\"hidden_states\"][-i][:,0,:] for i in range(1,5)], axis=-1)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    elif Config.encode_type == \"pooler\":\n",
        "        x = x[\"pooler_output\"]\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    elif Config.encode_type == \"logits\":\n",
        "        # TFAutoModelForSequenceClassificationの出力\n",
        "        x = x[\"logits\"]\n",
        "        output = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
        "\n",
        "    elif Config.encode_type == \"last_hidden_state_cnn\":\n",
        "        # encoderの最終出力を１次元のCNNで処理\n",
        "        x = x[\"last_hidden_state\"]\n",
        "        x = tf.keras.layers.Conv1D(\n",
        "            256, kernel_size=2, padding=\"same\", activation=\"relu\")(x)\n",
        "        x = tf.keras.layers.Conv1D(\n",
        "            1, kernel_size=2, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.GlobalMaxpooling1D()(x)\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "        \n",
        "    elif Config.encode_type == \"last_hidden_state_lstm\":\n",
        "        # encoderの最終出力を双方向LSTMで処理\n",
        "        x = x[\"last_hidden_state\"]\n",
        "        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(728))(x)\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"\n",
        "    使用するkerasモデルの全体像を定義します。\n",
        "    \"\"\"\n",
        "    # encoder\n",
        "    encoder = build_encoder()\n",
        "\n",
        "    # 入力\n",
        "    input_ids = tf.keras.layers.Input(shape=(Config.max_length, ), \n",
        "                                           dtype=tf.int32, \n",
        "                                           name='input_ids')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(Config.max_length, ),\n",
        "                                           dtype=tf.int32, \n",
        "                                           name='attention_mask')\n",
        "    \n",
        "    # ニューラルネットワーク全体構造\n",
        "    x = encoder(input_ids=input_ids, \n",
        "                attention_mask=attention_mask, \n",
        "                output_hidden_states=True)\n",
        "    output = neural_networks(x)\n",
        "\n",
        "    # kerasモデル化\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask],\n",
        "                                  outputs=[output])\n",
        "\n",
        "    # 最適化アルゴリズムと損失関数\n",
        "    optimizer = tfa.optimizers.AdamW(lr=Config.lr, weight_decay=Config.weight_decay)\n",
        "    loss = {\"bce\": tf.keras.losses.BinaryCrossentropy(),\n",
        "            \"weighted_bce\": weighted_binary_crossentropy(Config.loss_weight, Config.label_smoothing),\n",
        "            \"focal\": tfa.losses.SigmoidFocalCrossEntropy(alpha=0.98, gamma=2.0),\n",
        "            \"mse\": tf.keras.losses.MeanSquaredError()}\n",
        "\n",
        "    # 訓練中監視する指標\n",
        "    metrics = [tfa.metrics.FBetaScore(num_classes=1,\n",
        "                                      beta=6.0,\n",
        "                                      threshold=Config.temp_thre),\n",
        "               tf.keras.metrics.AUC(num_thresholds=200, curve='PR',\n",
        "                                    multi_label=False, label_weights=None)]\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss[Config.loss_fn], \n",
        "                  metrics=metrics)\n",
        "    # model.summary()\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ermBRSEwFryl"
      },
      "source": [
        "## 4.2 model取得\n",
        "環境に合わせてmodelを構築し取得します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIKSBtECF09M"
      },
      "source": [
        "def get_model():\n",
        "    \"\"\"\n",
        "    modeを取得\n",
        "    \"\"\"\n",
        "    if TPU:\n",
        "        tf.config.experimental_connect_to_cluster(TPU)\n",
        "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
        "        tpu_strategy = tf.distribute.TPUStrategy(TPU)\n",
        "        with tpu_strategy.scope():\n",
        "            model = build_model()\n",
        "    else:\n",
        "        model = build_model()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3yfkjoTW-pI"
      },
      "source": [
        "# ５. データ準備\n",
        "データをロードし、加工する為の関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpeaSp39-9ai"
      },
      "source": [
        "def get_data(file_name):\n",
        "    \"\"\"\n",
        "    csvファイルをロードし、前処理する。\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(os.path.join(INPUT, file_name))\n",
        "    if Config.debug:\n",
        "        df = df.sample(256, random_state=Config.seeds[0]).reset_index(drop=True)\n",
        "\n",
        "    # 前処理\n",
        "    df[\"text\"] = df[\"title\"] + \" \" + df[\"abstract\"].fillna(\"\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def skf(train_df, n_splits, random_state):\n",
        "    \"\"\"\n",
        "    層化K分割したindexのリストを返す。\n",
        "    n_splits<=1 の場合、全indexを返す。\n",
        "    \"\"\"\n",
        "    if n_splits > 1:\n",
        "        skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
        "        return list(skf.split(train_df, train_df[Config.target_col]))\n",
        "    else:\n",
        "        return train.index\n",
        "\n",
        "\n",
        "def tokenize_texts(texts, tokenizer):\n",
        "    \"\"\"\n",
        "    バッチ化された文字列をtoken化し、\n",
        "    keyが\"input_ids\"と\"attention_mask\"の辞書として返す。\n",
        "    \"\"\"\n",
        "    tokenized_dict = tokenizer.batch_encode_plus(\n",
        "        texts,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=Config.max_length,\n",
        "        return_token_type_ids=False,\n",
        "    )\n",
        "    return dict(tokenized_dict)\n",
        "\n",
        "\n",
        "def get_dataset(x, y=None, dataset=\"test\"):\n",
        "    \"\"\"\n",
        "    データをtf.data.Datasetの形式に変換する。\n",
        "    \"\"\"\n",
        "    if dataset==\"train\":\n",
        "        tr_ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        if Config.steps_per_epochs is not None:\n",
        "            tr_ds = tr_ds.repeat()\n",
        "        tr_ds = tr_ds.shuffle(2048)\n",
        "        tr_ds = tr_ds.batch(Config.train_batch_size)\n",
        "        tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return tr_ds\n",
        "\n",
        "    elif dataset==\"valid\":\n",
        "        val_ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        val_ds = val_ds.batch(Config.valid_batch_size)\n",
        "        val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return val_ds\n",
        "    \n",
        "    elif dataset==\"test\":\n",
        "        test_ds = tf.data.Dataset.from_tensor_slices(x)\n",
        "        test_ds = test_ds.batch(Config.test_batch_size)\n",
        "        test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return test_ds"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdAYKZGQaEjq"
      },
      "source": [
        "# ６. 訓練準備\n",
        "model訓練時に必要な関数を定義します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Bd-ENfaRef"
      },
      "source": [
        "## 6.1 カスタム損失関数\n",
        "自作の損失関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6AmkOBbSyfC"
      },
      "source": [
        "def weighted_binary_crossentropy(weight, label_smoothing):\n",
        "    \"\"\"\n",
        "    負例、正例にそれぞれ異なる重み付けをするcrossentropy損失関数\n",
        "    \"\"\"\n",
        "    weight = tf.convert_to_tensor(weight, dtype=tf.float32)\n",
        "\n",
        "    def _weighted_binary_crossentropy(target, output):\n",
        "        \"\"\"\n",
        "        label smoothingに対応した一般的なcrossentropy損失関数\n",
        "        keras公式の実装を参考に実装\n",
        "\n",
        "        \"\"\"\n",
        "        if Config.label_smoothing:\n",
        "            target = target * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "        target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "        target = tf.reshape(target, [-1])\n",
        "\n",
        "        output = tf.convert_to_tensor(output, dtype=tf.float32)\n",
        "        output = tf.reshape(output, [-1])\n",
        "        epsilon_ = K.epsilon()\n",
        "        output = tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
        "\n",
        "        bce = weight[1] * target * tf.math.log(output + K.epsilon())\n",
        "        bce += weight[0] * (1 - target) * tf.math.log(1 - output + K.epsilon())\n",
        "        return -bce\n",
        "\n",
        "    return _weighted_binary_crossentropy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZfk8-Abj2b"
      },
      "source": [
        "## 6.2 閾値最適化アルゴリズム\n",
        "閾値の最適化に必要な関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtGblpDAbkUR"
      },
      "source": [
        "def opt_fbeta_threshold(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    閾値のfbeta score最適化アルゴリズム\n",
        "    \"\"\"\n",
        "    def opt_(x): \n",
        "        return -fbeta_score(y_true, y_pred>=x, beta=7)\n",
        "    if Config.opt == \"minimize\":\n",
        "        result = minimize(opt_, x0=np.array([0.1]), method=\"Powell\")\n",
        "    elif Config.opt == \"minimize_scalar\":\n",
        "        result = minimize_scalar(opt_, bounds=(0.001, 0.85), method='bounded')\n",
        "    opted_threshold = result['x'].item()\n",
        "    return opted_threshold"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2pMn0fDiXSX"
      },
      "source": [
        "## 6.3 訓練結果\n",
        "訓練結果を取得したり表示する為の関数です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cBPoNKgEJ_k"
      },
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    最適化された閾値とその時のfbeta scoreを取得する。\n",
        "    \"\"\"\n",
        "    opted_thre = opt_fbeta_threshold(y_true, y_pred)\n",
        "    print(f\"opted threshold : {opted_thre}\")\n",
        "    score = fbeta_score(y_true, y_pred >= opted_thre, beta=7)\n",
        "    return score, opted_thre\n",
        "\n",
        "\n",
        "def get_result(y_true, y_pred, thresholds=None):\n",
        "    \"\"\"\n",
        "    様々な閾値とその時のfbetaスコアをpd.DataFrameとして返す。\n",
        "\n",
        "    1.　閾値のlistが与えられなかった場合\n",
        "    仮の閾値(Config.temp_thre)、最適化した閾値と\n",
        "    それらに対応するfbetaスコアを計算し、pd.DataFrameに格納する。\n",
        "\n",
        "    2.　閾値のlistが与えられた場合\n",
        "    その最大値、最小値、平均値、中央値と\n",
        "    それらに対応するfbetaスコアを計算し、上に追加する。\n",
        "    \"\"\"\n",
        "    thre_df = pd.DataFrame(columns=[\"threshold\", \"score\"])\n",
        "\n",
        "    naive_score = fbeta_score(y_true, y_pred >= Config.temp_thre, beta=6.0)\n",
        "    opted_score, opted_thre = metrics(y_true, y_pred)\n",
        "    type_list = [\"opted\", \"temporary\"]\n",
        "    thre_list = [opted_thre, Config.temp_thre]\n",
        "    score_list = [opted_score, naive_score]\n",
        "\n",
        "    if type(thresholds) is list:\n",
        "        thresholds = np.array(thresholds)\n",
        "        min_thre = thresholds.min()\n",
        "        max_thre = thresholds.max()\n",
        "        mean_thre = thresholds.mean()\n",
        "        med_thre = np.median(thresholds)\n",
        "\n",
        "        min_score = fbeta_score(y_true, y_pred >= min_thre, beta=6.0)\n",
        "        max_score = fbeta_score(y_true, y_pred >= max_thre, beta=6.0)\n",
        "        mean_score = fbeta_score(y_true, y_pred >= mean_thre, beta=6.0)\n",
        "        med_score = fbeta_score(y_true, y_pred >= med_thre, beta=6.0)\n",
        "\n",
        "        type_list += [\"min\", \"max\", \"mean\",\"median\"]\n",
        "        thre_list += [min_thre, max_thre, mean_thre, med_thre]\n",
        "        score_list += [min_score, max_score, mean_score, med_score] \n",
        "\n",
        "    thre_df[\"threshold\"] = thre_list\n",
        "    thre_df[\"score\"] = score_list\n",
        "    thre_df.index = type_list\n",
        "    return thre_df\n",
        "\n",
        "\n",
        "def visualize_confusion_matrix(\n",
        "        y_true,\n",
        "        pred_label,\n",
        "        height=.6,\n",
        "        labels=None):\n",
        "    \"\"\"\n",
        "    混合行列を表示する。\n",
        "    \"\"\"\n",
        "    conf = confusion_matrix(y_true=y_true,\n",
        "                            y_pred=pred_label,\n",
        "                            normalize='true')\n",
        "\n",
        "    n_labels = len(conf)\n",
        "    size = n_labels * height\n",
        "    fig, ax = plt.subplots(figsize=(size * 4, size * 3))\n",
        "    sns.heatmap(conf, cmap='Blues', ax=ax, annot=True, fmt='.2f')\n",
        "    ax.set_ylabel('Label')\n",
        "    ax.set_xlabel('Predict')\n",
        "\n",
        "    if labels is not None:\n",
        "        ax.set_yticklabels(labels)\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.tick_params('y', labelrotation=0)\n",
        "        ax.tick_params('x', labelrotation=90)\n",
        "\n",
        "    plt.show()\n",
        "    return fig"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSmt_CdkcD4I"
      },
      "source": [
        "## 6.4 class weight\n",
        "model.fit()の引数：class_weightに渡す値を取得します。<br>\n",
        "model.fit()は、学習時にはclass_weightに従ってlossに重みを乗算しますが、<br>\n",
        "検証データ評価時には、適用しないので、指標のval_lossは重みが乗算された値となりません。<br>\n",
        "故に、もしval_lossにも重み付けをする場合、損失関数は前述のweighted_binary_crossentropyを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXTkZh1_Gv9n"
      },
      "source": [
        "def get_class_weight(target, weight):\n",
        "    \"\"\"\n",
        "    class weightを取得する。\n",
        "    \"\"\"\n",
        "    if weight == \"balanced\":\n",
        "        class_weights = class_weight.compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.unique(target),\n",
        "            y=target)\n",
        "        class_weights = dict(enumerate(class_weights))\n",
        "    elif weight is None:\n",
        "        class_weights = None\n",
        "    else:\n",
        "        # ex) weight = {0:0.2, 1:0.98}\n",
        "        class_weights = weight\n",
        "    \n",
        "    return class_weights"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I-hS_nrqeRy"
      },
      "source": [
        "## 6.5 訓練関数、推論関数\n",
        "訓練、推論部分の手順を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brnebJMGtIds"
      },
      "source": [
        "def train_fn(train_df, valid_df, model, tokenizer, filepath):\n",
        "    \"\"\"\n",
        "    訓練関数\n",
        "    \"\"\"\n",
        "    # tf.data.Dataset準備\n",
        "    tr_text = tokenize_texts(texts=train_df[Config.text_col].tolist(), \n",
        "                             tokenizer=tokenizer)\n",
        "    val_text = tokenize_texts(texts=valid_df[Config.text_col].tolist(),\n",
        "                              tokenizer=tokenizer)\n",
        "\n",
        "    tr_ds = get_dataset(x=tr_text, \n",
        "                        y=train_df[Config.target_col].values, \n",
        "                        dataset=\"train\")\n",
        "    val_ds = get_dataset(x=val_text, \n",
        "                         y=valid_df[Config.target_col].values, \n",
        "                         dataset=\"valid\")\n",
        "\n",
        "    # callbacks\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath, \n",
        "        monitor=Config.check_monitor, \n",
        "        verbose=1, \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True,\n",
        "        mode=Config.check_mode\n",
        "        )\n",
        "    \n",
        "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=Config.patience\n",
        "        )\n",
        "    \n",
        "    # 訓練実行\n",
        "    history = model.fit(\n",
        "        tr_ds, \n",
        "        epochs=Config.epochs, \n",
        "        verbose=1, \n",
        "        callbacks=[checkpoint, earlystop],\n",
        "        validation_data=val_ds, \n",
        "        steps_per_epoch=Config.steps_per_epochs,\n",
        "        class_weight=get_class_weight(train_df[Config.target_col], \n",
        "                                      weight=Config.class_weight)\n",
        "        )\n",
        "    \n",
        "    return history\n",
        "\n",
        "\n",
        "def inference_fn(test_df, model, tokenizer, filepath):\n",
        "    \"\"\"\n",
        "    推論関数\n",
        "    \"\"\"\n",
        "    model.load_weights(filepath)\n",
        "    te_text = tokenize_texts(texts=test_df[Config.text_col].tolist(), \n",
        "                             tokenizer=tokenizer)\n",
        "    te_ds = get_dataset(x=te_text, y=None, dataset=\"test\")\n",
        "    preds = model.predict(te_ds)\n",
        "    return preds.reshape(-1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96mVy8p7tWek"
      },
      "source": [
        "## 6.6 交差検証関数\n",
        "cross validationの手順を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC8gn_UgtVZU"
      },
      "source": [
        "def train_cv(train_df, kf, metrics, name, dir):\n",
        "    \"\"\"\n",
        "    cross validationの実行関数 (train)\n",
        "    \"\"\"\n",
        "    # oofの予測確率(probability)と最適化された閾値の保存領域\n",
        "    oof_preds = np.zeros(len(train_df))\n",
        "    threshold_list = []\n",
        "\n",
        "    # k分割訓練\n",
        "    for i_fold, (tr_idx, val_idx) in enumerate(kf):\n",
        "        K.clear_session()\n",
        "        print(f\"\\n===== FOLD {i_fold+1} training =====\")\n",
        "        filepath = os.path.join(dir, f\"{name}_fold{i_fold+1}.h5\")\n",
        "\n",
        "        # model, tokenizerの準備\n",
        "        model = get_model()\n",
        "        tokenizer = transformers.AutoTokenizer.from_pretrained(Config.model)\n",
        "\n",
        "        # dataの分割\n",
        "        tr_df = train_df.iloc[tr_idx].reset_index()\n",
        "        val_df = train_df.iloc[val_idx].reset_index()\n",
        "        \n",
        "        # 学習済みモデルがあれば訓練しない\n",
        "        if not os.path.isfile(filepath):\n",
        "            history = train_fn(tr_df, val_df, model, tokenizer, filepath)\n",
        "            pd.DataFrame(history.history).to_csv(\n",
        "                os.path.join(LOG, f\"history{time_jp}_{i_fold+1}.csv\"), \n",
        "                index=False)\n",
        "\n",
        "        # oofの予測確率を計算し、\n",
        "        # 最適化された閾値とスコアをpd.DataFrameとして取得\n",
        "        preds = inference_fn(val_df, model, tokenizer, filepath)\n",
        "        thre_df = get_result(val_df[Config.target_col], preds)\n",
        "\n",
        "        # 最適化された閾値\n",
        "        opted_thre = thre_df[thre_df.index==\"opted\"].threshold.values[0]\n",
        "\n",
        "        logger.info(f\"===== fold {i_fold+1} result =====\")\n",
        "        logger.info(f\">>> {thre_df.to_dict()}\")\n",
        "\n",
        "        # oofの予測確率値と最適化された閾値を保存\n",
        "        oof_preds[val_idx] = preds\n",
        "        threshold_list.append(opted_thre)\n",
        "    \n",
        "    # oof全体の最適な閾値と、threshold_listから得た閾値でスコアを計算\n",
        "    thre_df = get_result(train_df[Config.target_col], oof_preds, threshold_list)\n",
        "    logger.info(f\"===== total result =====\")\n",
        "    logger.info(f\">>> threshold:{thre_df.to_dict()['threshold']}\")\n",
        "    logger.info(f\">>> score:{thre_df.to_dict()['score']}\")\n",
        "    return oof_preds, threshold_list\n",
        "\n",
        "\n",
        "def predict_cv(test_df, name):\n",
        "    \"\"\"\n",
        "    cross validationの実行関数 (test)\n",
        "    fold毎に保存したそれぞれのモデルでtestファイルに対し\n",
        "    probabilityを予測し、平均する\n",
        "    \"\"\"\n",
        "    preds_fold = []\n",
        "    for i_fold in range(Config.n_fold):\n",
        "        filepath = os.path.join(MODEL, f\"{name}_fold{i_fold+1}.h5\")\n",
        "        model = get_model()\n",
        "        tokenizer = transformers.AutoTokenizer.from_pretrained(Config.model)\n",
        "\n",
        "        preds = inference_fn(test_df, model, tokenizer, filepath)\n",
        "        preds_fold.append(preds)\n",
        "\n",
        "        logger.info(f\"===== fold{i_fold+1} inference =====\")\n",
        "    \n",
        "    preds = np.mean(preds_fold, axis=0)\n",
        "    return preds"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESLDR_wftqr1"
      },
      "source": [
        "# ７. 提出準備\n",
        "交差検証訓練の結果得た様々な閾値で、提出ファイルを作成する関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MLt675RpWqS"
      },
      "source": [
        "def submit_with_thresholds(type_list, threshold_list):\n",
        "    \"\"\"\n",
        "    様々な閾値を用いて、submitファイルを作成、保存\n",
        "    \"\"\"\n",
        "    name = f\"{Config.model.replace('/','-')}_{time_jp}\"\n",
        "    # testファイルに対して予測したprobability\n",
        "    prob_df = pd.read_csv(os.path.join(PROB, f\"prob_{name}.csv\"))\n",
        "    # submitファイルの雛形\n",
        "    submit_df = pd.read_csv(os.path.join(INPUT, \"sample_submit.csv\"), \n",
        "                            header=None, \n",
        "                            names=[\"id\", \"judgement\"])\n",
        "    if Config.debug:\n",
        "        submit_df = submit_df.iloc[get_data(Config.test_file).index.values]\n",
        "        \n",
        "    # submit\n",
        "    for key, threshold in zip(type_list, threshold_list):\n",
        "        predictions = (prob_df[f\"{name}_seed{Config.seeds[0]}\"].values >= threshold) * 1\n",
        "        filepath = f\"{name}_{key}.csv\"\n",
        "        submit_df[\"judgement\"] = predictions\n",
        "        submit_df.to_csv(os.path.join(SUBMIT, filepath), \n",
        "                         index=False, \n",
        "                         header=False)\n",
        "        logger.info(f\"saved file : {name}_{key}.csv\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdFJ4htCK-lx"
      },
      "source": [
        "# ８. 実行\n",
        "全体の手順を定義し、実行します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUI_ZPr6S2p3"
      },
      "source": [
        "def main():\n",
        "    # 訓練ごとに異なるファイル名を作成\n",
        "    model_name = f\"{Config.model.replace('/','-')}_{time_jp}\"\n",
        "    logger.info(f\"{model_name} TRAINING\")\n",
        "\n",
        "    # data準備\n",
        "    train_df = get_data(Config.train_file)\n",
        "    test_df = get_data(Config.test_file)\n",
        "\n",
        "    # 設定したseeds毎に訓練\n",
        "    oof_df = pd.DataFrame()\n",
        "    threshold_list = []\n",
        "    for seed in Config.seeds:\n",
        "        name = f\"{model_name}_seed{seed}\"\n",
        "        logger.info(f\"***** SEED{seed} *****\")\n",
        "        oof_preds, seed_thre_list = train_cv(\n",
        "            train_df, \n",
        "            kf=skf(train_df, n_splits=Config.n_fold, random_state=seed),\n",
        "            metrics=metrics, \n",
        "            name=name, \n",
        "            dir=MODEL)\n",
        "        oof_df[name] = oof_preds\n",
        "        threshold_list += seed_thre_list\n",
        "\n",
        "    # oofの予測値(probability)を保存\n",
        "    oof_df.to_csv(os.path.join(PROB, f\"oof_{model_name}.csv\"), index=False)\n",
        "    logger.info(f\"saved file : oof_{model_name}.csv\")\n",
        "\n",
        "    # トータルスコアを記録\n",
        "    y_true = train_df[Config.target_col].values\n",
        "    y_pred = oof_df.mean(axis=1).values\n",
        "    thre_df = get_result(y_true, y_pred, threshold_list)\n",
        "    \n",
        "    logger.info(f\"***** seeds total result *****\")\n",
        "    logger.info(f\">>> threshold:{thre_df.to_dict()['threshold']}\")\n",
        "    logger.info(f\">>> score:{thre_df.to_dict()['score']}\")\n",
        "\n",
        "    # 最適閾値で混合行列を表示\n",
        "    opted_thre = thre_df[thre_df.index==\"opted\"].threshold.values[0]\n",
        "    fig = visualize_confusion_matrix(y_true, y_pred>=opted_thre)\n",
        "    fig.savefig(os.path.join(LOG, f\"cm_{time_jp}.png\"), dpi=300)\n",
        "\n",
        "    # test予測値(probability)を計算\n",
        "    preds_df = pd.DataFrame()\n",
        "    for seed in Config.seeds:\n",
        "        name = f\"{model_name}_seed{seed}\"\n",
        "        preds = predict_cv(test_df, name)\n",
        "        preds_df[name] = preds\n",
        "\n",
        "    # test予測値(probability)を保存\n",
        "    preds_df.to_csv(os.path.join(PROB, f\"prob_{model_name}.csv\"), index=False)  \n",
        "    logger.info(f\"saved file : prob_{name}.csv\")\n",
        "\n",
        "    # submit\n",
        "    if Config.submit:\n",
        "        submit_with_thresholds(thre_df.index, thre_df.threshold)\n",
        "\n",
        "    # ハイパーパラメーターとkeras.modelの構造を記録\n",
        "    code_text = \"\"\n",
        "    with open(os.path.join(DRIVE, \"medical_bert_tf.ipynb\"), mode=\"r\") as f:\n",
        "        code = f.read()\n",
        "\n",
        "    for i in [2,3]:\n",
        "        code_text += \"\".join(json.loads(code)[\"cells\"][i][\"source\"])+\"\\n\\n\"\n",
        "\n",
        "    logger.info(code_text)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51KXC98yt7CB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da5444aa86194ae68764ae89fa114b8b",
            "3653f1ea23f145a099dc15677e7f7a38",
            "d64fe5a74df944559d2a6c51092dbfd0",
            "2680ec75590c41b6899d6f4936fff83b",
            "e3250ab924024f088708cb373bc50620",
            "423added286e41ae9363049c1819ce9f",
            "e480d899a92642aa9f89d34c6b65b8f2",
            "406a68a9513a4361a64cb8111485442f",
            "a273af078c894fa09ec41c6809042008",
            "4e1f6a4d95994309a4e0c8751ae13c1c",
            "e4a7049ff1b544da91a78e926c2bc838",
            "2a4865a8ddbb46e9849fc2ee4038ee19",
            "8e4347f13a9d4237bc0b7350ed8c8f42",
            "3110a80401554b67abb9378bc98514aa",
            "1ec7f6f5a28c4ea5864bf29a73a94025",
            "8c607859e4c24b53a3414b778b6af9b7",
            "b9fedbcac3ce42c891df7fc03c3803e9",
            "b5ee89f3cd4c485da8ee64931c567c53",
            "0b3241ff7be145a7aa08fb0ac26fbfd9",
            "3dd20968a0ef4a0aaa275cdea3efb3fd",
            "0bfc8094a05a4af0ab684f4a1fbc2a2f",
            "835003a9c36f473e81c363591348a379",
            "9dd13d4edca94bf3a5862fc4af4198ef",
            "55e5b83850b14160a542a9aedb418ece",
            "b50d3364b66a4051b86042fe18103775",
            "4d3fbc2c65ee4d2e9b11b2c72c4fef91",
            "bc14e38fad904013a563949e3a667830",
            "c6212a47c4a749bc97ffafa1af5777e0",
            "20e61f627f6a4f06944c18be6541497c",
            "41383973c98946ac8db3108e96658ee5",
            "bc6aee2eacac4b279e3880bc93130c36",
            "3f997e0a13444f18ab800ede853e2431",
            "be177624ef35480c86c69159f500079b"
          ]
        },
        "outputId": "3b4ae163-2006-4b2f-f93b-01cce27f3642"
      },
      "source": [
        "main()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FOLD 1 training =====\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "DEBUG:filelock:Attempting to acquire lock 139965667215696 on /root/.cache/huggingface/transformers/ece5e89bab3b63a40e413c7f599e6081663cad06eb394e48d5023930733d15a3.ad895c9bc4687ffedea1a4cc498ac3f67ebd2083732981c2a06f548cde7d6582.lock\n",
            "DEBUG:filelock:Lock 139965667215696 acquired on /root/.cache/huggingface/transformers/ece5e89bab3b63a40e413c7f599e6081663cad06eb394e48d5023930733d15a3.ad895c9bc4687ffedea1a4cc498ac3f67ebd2083732981c2a06f548cde7d6582.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da5444aa86194ae68764ae89fa114b8b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139965667215696 on /root/.cache/huggingface/transformers/ece5e89bab3b63a40e413c7f599e6081663cad06eb394e48d5023930733d15a3.ad895c9bc4687ffedea1a4cc498ac3f67ebd2083732981c2a06f548cde7d6582.lock\n",
            "DEBUG:filelock:Lock 139965667215696 released on /root/.cache/huggingface/transformers/ece5e89bab3b63a40e413c7f599e6081663cad06eb394e48d5023930733d15a3.ad895c9bc4687ffedea1a4cc498ac3f67ebd2083732981c2a06f548cde7d6582.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 139965666108560 on /root/.cache/huggingface/transformers/1414d44e1692194ad8c160a4bc51d9bd98da5365a8c08e5182731cf84eb134f5.02df0b4a307fbaed7d1fe54d7b95b850ac1f31e1331142c3da71b82b0d48f77d.lock\n",
            "DEBUG:filelock:Lock 139965666108560 acquired on /root/.cache/huggingface/transformers/1414d44e1692194ad8c160a4bc51d9bd98da5365a8c08e5182731cf84eb134f5.02df0b4a307fbaed7d1fe54d7b95b850ac1f31e1331142c3da71b82b0d48f77d.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a4865a8ddbb46e9849fc2ee4038ee19",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139965666108560 on /root/.cache/huggingface/transformers/1414d44e1692194ad8c160a4bc51d9bd98da5365a8c08e5182731cf84eb134f5.02df0b4a307fbaed7d1fe54d7b95b850ac1f31e1331142c3da71b82b0d48f77d.lock\n",
            "DEBUG:filelock:Lock 139965666108560 released on /root/.cache/huggingface/transformers/1414d44e1692194ad8c160a4bc51d9bd98da5365a8c08e5182731cf84eb134f5.02df0b4a307fbaed7d1fe54d7b95b850ac1f31e1331142c3da71b82b0d48f77d.lock\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "DEBUG:filelock:Attempting to acquire lock 139964771202896 on /root/.cache/huggingface/transformers/e1dbe55c1d83f79c61148b28fbe20bfbb6aeb2f7163225830b3063fda58425e5.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "DEBUG:filelock:Lock 139964771202896 acquired on /root/.cache/huggingface/transformers/e1dbe55c1d83f79c61148b28fbe20bfbb6aeb2f7163225830b3063fda58425e5.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dd13d4edca94bf3a5862fc4af4198ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139964771202896 on /root/.cache/huggingface/transformers/e1dbe55c1d83f79c61148b28fbe20bfbb6aeb2f7163225830b3063fda58425e5.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "DEBUG:filelock:Lock 139964771202896 released on /root/.cache/huggingface/transformers/e1dbe55c1d83f79c61148b28fbe20bfbb6aeb2f7163225830b3063fda58425e5.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=float64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=float64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=float64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=float64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - ETA: 0s - loss: 0.7862 - fbeta_score: 0.6510 - auc: 0.0482  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=float64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 121s 16s/step - loss: 0.7862 - fbeta_score: 0.6510 - auc: 0.0482 - val_loss: 1.1678 - val_fbeta_score: 0.6006 - val_auc: 0.1510\n",
            "\n",
            "Epoch 00001: val_fbeta_score improved from -inf to 0.60065, saving model to /content/drive/MyDrive/signate/medical_paper/model/dmis-lab-biobert-base-cased-v1.2_tf/dmis-lab-biobert-base-cased-v1.2_20211103_1003_seed21_fold1.h5\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.6579 - fbeta_score: 0.6453 - auc: 0.1983 - val_loss: 0.4965 - val_fbeta_score: 0.6006 - val_auc: 0.1452\n",
            "\n",
            "Epoch 00002: val_fbeta_score did not improve from 0.60065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n",
            "INFO:__main__:[2021-11-03 10:08:07] - ===== fold 1 result =====\n",
            "INFO:__main__:[2021-11-03 10:08:07] - >>> {'threshold': {'opted': -1.4994280624162823, 'temporary': 0.1}, 'score': {'opted': 0.6702412868632708, 'temporary': 0.6006493506493507}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opted threshold : -1.4994280624162823\n",
            "\n",
            "===== FOLD 2 training =====\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.118.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.118.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=float64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=float64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=float64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=float64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - ETA: 0s - loss: 0.8253 - fbeta_score: 0.6006 - auc: 0.0539  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=float64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 122s 16s/step - loss: 0.8253 - fbeta_score: 0.6006 - auc: 0.0539 - val_loss: 0.9947 - val_fbeta_score: 0.6453 - val_auc: 0.0792\n",
            "\n",
            "Epoch 00001: val_fbeta_score improved from -inf to 0.64535, saving model to /content/drive/MyDrive/signate/medical_paper/model/dmis-lab-biobert-base-cased-v1.2_tf/dmis-lab-biobert-base-cased-v1.2_20211103_1003_seed21_fold2.h5\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5388 - fbeta_score: 0.6026 - auc: 0.2816 - val_loss: 0.4076 - val_fbeta_score: 0.6453 - val_auc: 0.0996\n",
            "\n",
            "Epoch 00002: val_fbeta_score did not improve from 0.64535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n",
            "INFO:__main__:[2021-11-03 10:11:57] - ===== fold 2 result =====\n",
            "INFO:__main__:[2021-11-03 10:11:57] - >>> {'threshold': {'opted': -1.4994280624162823, 'temporary': 0.1}, 'score': {'opted': 0.7109004739336493, 'temporary': 0.6453488372093024}}\n",
            "INFO:__main__:[2021-11-03 10:11:57] - ===== total result =====\n",
            "INFO:__main__:[2021-11-03 10:11:57] - >>> threshold:{'opted': -1.4994280624162823, 'temporary': 0.1, 'min': -1.4994280624162823, 'max': -1.4994280624162823, 'mean': -1.4994280624162823, 'median': -1.4994280624162823}\n",
            "INFO:__main__:[2021-11-03 10:11:57] - >>> score:{'opted': 0.6918238993710691, 'temporary': 0.6242331288343558, 'min': 0.6242331288343558, 'max': 0.6242331288343558, 'mean': 0.6242331288343558, 'median': 0.6242331288343558}\n",
            "INFO:__main__:[2021-11-03 10:11:57] - saved file : oof_dmis-lab-biobert-base-cased-v1.2_20211103_1003.csv\n",
            "INFO:__main__:[2021-11-03 10:11:57] - ***** seeds total result *****\n",
            "INFO:__main__:[2021-11-03 10:11:57] - >>> threshold:{'opted': -1.4994280624162823, 'temporary': 0.1, 'min': -1.4994280624162823, 'max': -1.4994280624162823, 'mean': -1.4994280624162823, 'median': -1.4994280624162823}\n",
            "INFO:__main__:[2021-11-03 10:11:57] - >>> score:{'opted': 0.6918238993710691, 'temporary': 0.6242331288343558, 'min': 0.6242331288343558, 'max': 0.6242331288343558, 'mean': 0.6242331288343558, 'median': 0.6242331288343558}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opted threshold : -1.4994280624162823\n",
            "opted threshold : -1.4994280624162823\n",
            "opted threshold : -1.4994280624162823\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 345.6x259.2 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.118.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.118.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n",
            "INFO:__main__:[2021-11-03 10:13:34] - ===== fold1 inference =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.118.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.118.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.118.194:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n",
            "INFO:__main__:[2021-11-03 10:15:29] - ===== fold2 inference =====\n",
            "INFO:__main__:[2021-11-03 10:15:29] - saved file : prob_dmis-lab-biobert-base-cased-v1.2_20211103_1003_seed21.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - saved file : dmis-lab-biobert-base-cased-v1.2_20211103_1003_opted.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - saved file : dmis-lab-biobert-base-cased-v1.2_20211103_1003_temporary.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - saved file : dmis-lab-biobert-base-cased-v1.2_20211103_1003_min.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - saved file : dmis-lab-biobert-base-cased-v1.2_20211103_1003_max.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - saved file : dmis-lab-biobert-base-cased-v1.2_20211103_1003_mean.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - saved file : dmis-lab-biobert-base-cased-v1.2_20211103_1003_median.csv\n",
            "INFO:__main__:[2021-11-03 10:15:31] - class Config:\n",
            "    model = \"dmis-lab/biobert-base-cased-v1.2\" #@param\n",
            "    from_pt = True #@param {\"type\":\"boolean\"}\n",
            "    encode_type = \"cls_cat\" #@param {\"type\",\"string\"} [\"cls\",\"cls_cat\",\"pooler\",\"logits\", \"last_hidden_state_cnn\", \"last_hidden_state_lstm\"]\n",
            "\n",
            "    max_length = 512 #@param {\"type\":\"integer\"}\n",
            "    lr = 0.00002\n",
            "    weight_decay = 1e-5\n",
            "    opt = \"minimize\"  #@param {\"type\":\"string\"} [\"minimize_scalar\",\"minimize\"]\n",
            "    n_fold = 5 #@param\n",
            "    epochs = 15 #@param {\"type\":\"slider\"}\n",
            "    patience =  4#@param\n",
            "    check_monitor = \"val_fbeta_score\" #@param {\"type\":\"string\"} [\"val_loss\",\"val_fbeta_score\",\"val_auc\"]\n",
            "    check_mode = \"max\" #@param {\"type\":\"string\"} [\"auto\", \"max\"]\n",
            "    \n",
            "    train_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
            "    valid_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
            "    test_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
            "    steps_per_epochs = None #(27145 * (n_fold - 1) / n_fold) // train_batch_size\n",
            "    train_file = \"ps_train.csv\" #@param\n",
            "    test_file = \"ps_test.csv\" #@param\n",
            "    target_col = \"judgement\"\n",
            "    text_col = \"summary\"  #@param {\"type\":\"string\"} [\"text\",\"summary\"]\n",
            "    seeds = [21]\n",
            "\n",
            "    loss_fn = \"bce\" #@param {\"type\":\"string\"} [\"bce\", \"weighted_bce\", \"focal\"]\n",
            "    loss_weight = [1,50] #@param\n",
            "    class_weight = \"balanced\" #@param {\"type\":\"raw\"} \n",
            "    sample_weight = None #@param    \n",
            "    label_smoothing = 0 #@param\n",
            "    \n",
            "    submit = True #@param {\"type\":\"boolean\"}\n",
            "    debug = False  #@param {\"type\":\"boolean\"}\n",
            "    temp_thre = 0.1 #@param\n",
            "\n",
            "if Config.debug:\n",
            "    Config.epochs = 2\n",
            "    Config.n_fold = 2\n",
            "\n",
            "time_jp = (datetime.datetime.now() + \n",
            "           datetime.timedelta(hours=9)).strftime('%Y%m%d_%H%M')\n",
            "# time_jp = '20210926_1749' #@param\n",
            "time_jp\n",
            "\n",
            "def build_auto_model():\n",
            "    \n",
            "    # encoder\n",
            "    if Config.encode_type == \"logits\":\n",
            "        encoder = (\n",
            "            transformers\n",
            "            .TFAutoModelForSequenceClassification\n",
            "            .from_pretrained(Config.model, num_labels=1, from_pt=Config.from_pt)\n",
            "        )\n",
            "    elif Config.encode_type == \"cls_cat\":\n",
            "        config = transformers.AutoConfig.from_pretrained(Config.model,\n",
            "                                                         output_hidden_states=True)\n",
            "        encoder = (\n",
            "            transformers\n",
            "            .TFAutoModel\n",
            "            .from_pretrained(Config.model, config=config, from_pt=Config.from_pt)\n",
            "        )\n",
            "\n",
            "    else:\n",
            "        encoder = (\n",
            "            transformers\n",
            "            .TFAutoModel\n",
            "            .from_pretrained(Config.model, from_pt=Config.from_pt)\n",
            "        )\n",
            "    \n",
            "    input_word_ids = tf.keras.layers.Input(shape=(Config.max_length, ), dtype=tf.int32, name='input_ids')\n",
            "    attention_mask = tf.keras.layers.Input(shape=(Config.max_length, ), dtype=tf.int32, name='attention_mask')\n",
            "    x = encoder(input_word_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
            "\n",
            "    # output token type\n",
            "    if Config.encode_type == \"cls\":\n",
            "        x = x[0][:, 0, :]  # cls token\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "\n",
            "    elif Config.encode_type == \"cls_cat\":\n",
            "        x = tf.concat([x[\"hidden_states\"][-i][:,0,:] for i in range(1,5)], axis=-1)\n",
            "        x = tf.keras.layers.Dropout(0.2)(x)\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "\n",
            "    elif Config.encode_type == \"pooler\":\n",
            "        x = x[\"pooler_output\"]\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "\n",
            "    elif Config.encode_type == \"logits\":\n",
            "        x = x.logits\n",
            "        output = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
            "\n",
            "    elif Config.encode_type == \"last_hidden_state_cnn\":\n",
            "        x = x.last_hidden_state\n",
            "        x = tf.keras.layers.Conv1D(\n",
            "            256, kernel_size=2, padding=\"same\", activation=\"relu\")(x)\n",
            "        x = tf.keras.layers.Conv1D(\n",
            "            1, kernel_size=2, padding=\"same\")(x)\n",
            "        x = tf.keras.layers.GlobalMaxpooling1D()(x)\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "        \n",
            "    elif Config.encode_type == \"last_hidden_state_lstm\":\n",
            "        x = x.last_hidden_state\n",
            "        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(728))(x)\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "        \n",
            "\n",
            "    model = tf.keras.models.Model(inputs=[input_word_ids, attention_mask],\n",
            "                                  outputs=[output])\n",
            "\n",
            "    optimizer = tfa.optimizers.AdamW(lr=Config.lr, weight_decay=Config.weight_decay)\n",
            "\n",
            "    loss = {\"bce\": tf.keras.losses.BinaryCrossentropy(),\n",
            "            \"weighted_bce\": weighted_binary_crossentropy(Config.loss_weight, Config.label_smoothing),\n",
            "            \"focal\": tfa.losses.SigmoidFocalCrossEntropy(alpha=0.98, gamma=2.0),\n",
            "            \"mse\": tf.keras.losses.MeanSquaredError()}\n",
            "\n",
            "    metrics = [tfa.metrics.FBetaScore(num_classes=1,\n",
            "                                      beta=7.0,\n",
            "                                      threshold=Config.temp_thre),\n",
            "               tf.keras.metrics.AUC(num_thresholds=200, curve='PR',\n",
            "                                    multi_label=False, label_weights=None)]\n",
            "\n",
            "    model.compile(optimizer=optimizer,\n",
            "                  loss=loss[Config.loss_fn], \n",
            "                  metrics=metrics)\n",
            "    # model.summary()\n",
            "    return model\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}