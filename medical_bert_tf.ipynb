{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical_bert_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ermBRSEwFryl",
        "v1YRVdjyrNbT",
        "exz-Kb1SP_W_",
        "Y_2crOsGQFyc",
        "AW1Mxf8zRupw",
        "X3yfkjoTW-pI",
        "9_Bd-ENfaRef",
        "ZVZfk8-Abj2b",
        "i2pMn0fDiXSX",
        "ESLDR_wftqr1"
      ],
      "toc_visible": true,
      "mount_file_id": "1BxS3wP9hkIQ5a-ZuxhtHFKyp0Xb5aRSZ",
      "authorship_tag": "ABX9TyMowGLt16irs5OoIxM8GR8c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyanakai/medical_paper_classification/blob/main/medical_bert_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmYQsaQ212VL"
      },
      "source": [
        "<h1>医学論文の自動仕分けチャレンジ 訓練</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB9bBdbU17Wm"
      },
      "source": [
        "# １. はじめに\n",
        "\n",
        "本ノートブックでは、SIGNATE上で開催された文章分類コンペティション[医学論文の自動仕分けチャレンジ](https://signate.jp/competitions/471)のタスクに基づいて、BERTモデルを訓練します。<br>\n",
        "データは[medical_EDA.ipynb](https://github.com/Tyanakai/medical_paper_classification/blob/main/medical_EDA.ipynb)において前処理し保存したファイル(`p_train.csv`,`p_test.csv`)を使用します。<br>\n",
        "使用するモデルは、以下の通りです。\n",
        "<br>\n",
        "\n",
        "*   [BioELECTRA](https://github.com/kamalkraj/BioELECTRA)\n",
        "*   [SapBERT](https://huggingface.co/cambridgeltl/SapBERT-from-PubMedBERT-fulltext)\n",
        "*   [PubMedBERT](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext)\n",
        "*   [BioBERT](https://huggingface.co/dmis-lab/biobert-base-cased-v1.2)\n",
        "\n",
        "尚、colabratory上で、ランタイムのタイプをTPUに設定した状態での実行を想定しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFGzxVit4NKR"
      },
      "source": [
        "# ２. 事前に完了していること\n",
        "\n",
        "- [medical_EDA.ipynb](https://github.com/Tyanakai/medical_paper_classification/blob/main/medical_EDA.ipynb)を実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5bLdmt7G5xD"
      },
      "source": [
        "# ３. 環境準備\n",
        "訓練環境を構築します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1YRVdjyrNbT"
      },
      "source": [
        "## 3.1 ライブラリ準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHvKphT8BMKE"
      },
      "source": [
        "! pip install -q transformers\n",
        "! pip install -q tensorflow-addons\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.optimize import minimize\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "import transformers\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exz-Kb1SP_W_"
      },
      "source": [
        "## 3.2 TPU設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPdMBltfWeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e098997f-3217-469f-f187-08d1c8f341f5"
      },
      "source": [
        "try:\n",
        "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', TPU.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    TPU = None\n",
        "    print('INFO: Not connected to a TPU runtime')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.38.49.226:8470']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B59L5n9DQjEc"
      },
      "source": [
        "## 3.3 Google Driveマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g26P5nFOQrRl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajhXgI0Celo0"
      },
      "source": [
        "## 3.4 ハイパーパラメータ設定\n",
        "ハイパーパラメータを設定します。\n",
        "\n",
        "|パラメータ名|説明|\n",
        "|:-|:-|\n",
        "|model| Hugging Face内のパス。ローカルフォルダやファイルの命名にも用いる|\n",
        "|from_pt|tf_model.h5が公開されていない場合、Trueとする|\n",
        "|encode_type|encoderの出力形式。cf.) 4.1 model定義|\n",
        "|-|-|\n",
        "|max_length|入力する最大token数|\n",
        "|opt|使用するscipy.optimizeのアルゴリズム|\n",
        "|patience|EarlyStoppingのパラメータ。訓練早期終了を延期するepoch数|\n",
        "|check_monitor|ModelCheckpointのパラメータ。保存するmodelの選定指標|\n",
        "|check_mode|check_monitorでval_aucを選択した場合\"max\"でないと正常に機能しない\n",
        "|-|-|\n",
        "|loss_fn|損失関数。\"bce\" : binary crossentropy, \"focal\" : focal binary crossentropy| \n",
        "|loss_weight|loss_fnをweighted_bceにした場合、負例、正例にそれぞれ乗算する重みを設定する|\n",
        "|class_weight|model.fit()時にclass別に重みを乗算する。loss_weightと同時に使用しない。cf.) 6.4 class weight|\n",
        "|-|-|\n",
        "|target_col|判定するラベル列|\n",
        "|text_col|入力として用いる列|\n",
        "|-|-|\n",
        "|temp_thre|仮の閾値|\n",
        "|-|-|\n",
        "|time_jp|日本標準時。ファイル名を区別するために使用|\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBKkHi54SQSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "016bae99-03dd-4484-d05c-7d31e60bb1ea"
      },
      "source": [
        "class Config:\n",
        "    model = \"dmis-lab/biobert-base-cased-v1.2\" #@param\n",
        "    from_pt = True #@param {\"type\":\"boolean\"}\n",
        "    encode_type = \"cls_cat\" #@param {\"type\",\"string\"} [\"cls\",\"cls_cat\",\"pooler\",\"logits\", \"last_hidden_state_cnn\", \"last_hidden_state_lstm\"]\n",
        "\n",
        "    max_length = 512 #@param {\"type\":\"integer\"}\n",
        "    lr = 0.00002\n",
        "    weight_decay = 1e-5\n",
        "    opt = \"minimize\"  #@param {\"type\":\"string\"} [\"minimize_scalar\",\"minimize\"]\n",
        "    n_fold = 5 #@param\n",
        "    epochs = 15 #@param {\"type\":\"slider\"}\n",
        "    patience = 4 #@param\n",
        "    check_monitor = \"val_fbeta_score\" #@param {\"type\":\"string\"} [\"val_loss\",\"val_fbeta_score\",\"val_auc\"]\n",
        "    check_mode = \"max\" #@param {\"type\":\"string\"} [\"auto\", \"max\"]\n",
        "    \n",
        "    train_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
        "    valid_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
        "    test_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
        "    steps_per_epochs = None #(27145 * (n_fold - 1) / n_fold) // train_batch_size\n",
        "    train_file = \"p_train.csv\" #@param\n",
        "    test_file = \"p_test.csv\" #@param\n",
        "    target_col = \"judgement\"\n",
        "    text_col = \"text\"\n",
        "    seeds = [21]\n",
        "\n",
        "    loss_fn = \"bce\" #@param {\"type\":\"string\"} [\"bce\", \"weighted_bce\", \"focal\"]\n",
        "    loss_weight = [1, 50] #@param\n",
        "    class_weight = \"balanced\" #@param {\"type\":\"raw\"}     \n",
        "    label_smoothing = 0 #@param\n",
        "    \n",
        "    submit = True #@param {\"type\":\"boolean\"}\n",
        "    debug = True  #@param {\"type\":\"boolean\"}\n",
        "    temp_thre = 0.1 #@param\n",
        "\n",
        "if Config.debug:\n",
        "    Config.epochs = 2\n",
        "    Config.n_fold = 2\n",
        "\n",
        "time_jp = (datetime.datetime.now() + \n",
        "           datetime.timedelta(hours=9)).strftime('%Y%m%d_%H%M')\n",
        "# time_jp = '20210926_1749' #@param\n",
        "time_jp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'20211102_2135'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_2crOsGQFyc"
      },
      "source": [
        "## 3.5 pathの設定\n",
        "pathを設定し必要なフォルダを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O9-YHdofe6H"
      },
      "source": [
        "DRIVE = \"/content/drive/MyDrive/signate/medical_paper\"\n",
        "INPUT = os.path.join(DRIVE, \"input\")\n",
        "OUTPUT = os.path.join(DRIVE, \"output\")\n",
        "LOG = os.path.join(OUTPUT, f\"{Config.model.replace('/','-')}_tf\")\n",
        "MODEL = os.path.join(DRIVE, \"model\", f\"{Config.model.replace('/','-')}_tf\")\n",
        "SUBMIT = os.path.join(DRIVE, \"submit\") # 提出ファイルを保存するフォルダ\n",
        "PROB = os.path.join(DRIVE, \"prob\") # 予測確率値(probability)を保存するフォルダ\n",
        "\n",
        "for folder in [DRIVE, INPUT, OUTPUT, LOG, MODEL, SUBMIT, PROB]:\n",
        "    os.makedirs(folder, exist_ok=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW1Mxf8zRupw"
      },
      "source": [
        "## 3.6 loggingの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nQXayCa7XaO"
      },
      "source": [
        "class Logger:\n",
        "    \"\"\"\n",
        "    log を残す用のクラス\n",
        "    path : logを保存するフォルダ \n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        self.general_logger = logging.getLogger(__name__)\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        file_general_handler = logging.FileHandler(os.path.join(path, f'Experiment{time_jp}.log'))\n",
        "        if len(self.general_logger.handlers) == 0:\n",
        "            # self.general_logger.addHandler(stream_handler)\n",
        "            self.general_logger.addHandler(file_general_handler)\n",
        "            self.general_logger.setLevel(logging.INFO)\n",
        "\n",
        "    def info(self, message):\n",
        "        # 時刻とmessageを記録\n",
        "        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n",
        "\n",
        "    @staticmethod\n",
        "    def now_string():\n",
        "        # 時刻を取得\n",
        "        cur_time = datetime.datetime.now() + datetime.timedelta(hours=9)\n",
        "        return cur_time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "logger = Logger(LOG)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWzk922D68L"
      },
      "source": [
        "# ４. model, tokenizer準備\n",
        "訓練するmodelやtokenizerを取得する関数を定義します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC2-ygoEFkBk"
      },
      "source": [
        "## 4.1 model定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqEOf5pnSx18"
      },
      "source": [
        "def build_encoder():\n",
        "    \"\"\"\n",
        "    encoderの出力形式(Config.encode_type)に従って\n",
        "    設定を変化させたencoderを返します。\n",
        "    \"\"\"\n",
        "    if Config.encode_type == \"logits\":\n",
        "        encoder = (\n",
        "            transformers\n",
        "            .TFAutoModelForSequenceClassification\n",
        "            .from_pretrained(Config.model, num_labels=1, from_pt=Config.from_pt)\n",
        "        )\n",
        "\n",
        "    elif Config.encode_type == \"cls_cat\":\n",
        "        # 最終層以外のhidden_statesを出力する為のconfig\n",
        "        config = (\n",
        "            transformers.\n",
        "            AutoConfig.\n",
        "            from_pretrained(Config.model, output_hidden_states=True)\n",
        "        )\n",
        "\n",
        "        encoder = (\n",
        "            transformers\n",
        "            .TFAutoModel\n",
        "            .from_pretrained(Config.model, config=config, from_pt=Config.from_pt)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        encoder = (\n",
        "            transformers\n",
        "            .TFAutoModel\n",
        "            .from_pretrained(Config.model, from_pt=Config.from_pt)\n",
        "        )\n",
        "\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def neural_networks(x):\n",
        "    \"\"\"\n",
        "    encoderの出力形式(Config.encode_type)に従って\n",
        "    encoder以降の構造を定義します。\n",
        "    \"\"\"\n",
        "\n",
        "    if Config.encode_type == \"cls\":\n",
        "        # cls tokenを使用\n",
        "        x = x[0][:, 0, :]\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    elif Config.encode_type == \"cls_cat\":\n",
        "        # encoderの最終四層分のcls tokenを連結\n",
        "        x = tf.concat([x[\"hidden_states\"][-i][:,0,:] for i in range(1,5)], axis=-1)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    elif Config.encode_type == \"pooler\":\n",
        "        x = x[\"pooler_output\"]\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    elif Config.encode_type == \"logits\":\n",
        "        # TFAutoModelForSequenceClassificationの出力\n",
        "        x = x[\"logits\"]\n",
        "        output = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
        "\n",
        "    elif Config.encode_type == \"last_hidden_state_cnn\":\n",
        "        # encoderの最終出力を１次元のCNNで処理\n",
        "        x = x[\"last_hidden_state\"]\n",
        "        x = tf.keras.layers.Conv1D(\n",
        "            256, kernel_size=2, padding=\"same\", activation=\"relu\")(x)\n",
        "        x = tf.keras.layers.Conv1D(\n",
        "            1, kernel_size=2, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.GlobalMaxpooling1D()(x)\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "        \n",
        "    elif Config.encode_type == \"last_hidden_state_lstm\":\n",
        "        # encoderの最終出力を双方向LSTMで処理\n",
        "        x = x[\"last_hidden_state\"]\n",
        "        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(728))(x)\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"\n",
        "    使用するkerasモデルの全体像を定義します。\n",
        "    \"\"\"\n",
        "    # encoder\n",
        "    encoder = build_encoder()\n",
        "\n",
        "    # 入力\n",
        "    input_ids = tf.keras.layers.Input(shape=(Config.max_length, ), \n",
        "                                           dtype=tf.int32, \n",
        "                                           name='input_ids')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(Config.max_length, ),\n",
        "                                           dtype=tf.int32, \n",
        "                                           name='attention_mask')\n",
        "    \n",
        "    # ニューラルネットワーク全体構造\n",
        "    x = encoder(input_ids=input_ids, \n",
        "                attention_mask=attention_mask, \n",
        "                output_hidden_states=True)\n",
        "    output = neural_networks(x)\n",
        "\n",
        "    # kerasモデル化\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask],\n",
        "                                  outputs=[output])\n",
        "\n",
        "    # 最適化アルゴリズムと損失関数\n",
        "    optimizer = tfa.optimizers.AdamW(lr=Config.lr, weight_decay=Config.weight_decay)\n",
        "    loss = {\"bce\": tf.keras.losses.BinaryCrossentropy(),\n",
        "            \"weighted_bce\": weighted_binary_crossentropy(Config.loss_weight, Config.label_smoothing),\n",
        "            \"focal\": tfa.losses.SigmoidFocalCrossEntropy(alpha=0.98, gamma=2.0),\n",
        "            \"mse\": tf.keras.losses.MeanSquaredError()}\n",
        "\n",
        "    # 訓練中監視する指標\n",
        "    metrics = [tfa.metrics.FBetaScore(num_classes=1,\n",
        "                                      beta=6.0,\n",
        "                                      threshold=Config.temp_thre),\n",
        "               tf.keras.metrics.AUC(num_thresholds=200, curve='PR',\n",
        "                                    multi_label=False, label_weights=None)]\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss[Config.loss_fn], \n",
        "                  metrics=metrics)\n",
        "    # model.summary()\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ermBRSEwFryl"
      },
      "source": [
        "## 4.2 model取得\n",
        "環境に合わせてmodelを構築し取得します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIKSBtECF09M"
      },
      "source": [
        "def get_model():\n",
        "    \"\"\"\n",
        "    modeを取得\n",
        "    \"\"\"\n",
        "    if TPU:\n",
        "        tf.config.experimental_connect_to_cluster(TPU)\n",
        "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
        "        tpu_strategy = tf.distribute.TPUStrategy(TPU)\n",
        "        with tpu_strategy.scope():\n",
        "            model = build_model()\n",
        "    else:\n",
        "        model = build_model()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3yfkjoTW-pI"
      },
      "source": [
        "# ５. データ準備\n",
        "データをロードし、加工する為の関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpeaSp39-9ai"
      },
      "source": [
        "def get_data(file_name):\n",
        "    \"\"\"\n",
        "    csvファイルをロードし、前処理する。\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(os.path.join(INPUT, file_name))\n",
        "    if Config.debug:\n",
        "        df = df.sample(256, random_state=Config.seeds[0]).reset_index(drop=True)\n",
        "\n",
        "    # 前処理\n",
        "    df[\"text\"] = df[\"title\"] + \" \" + df[\"abstract\"].fillna(\"\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def skf(train_df, n_splits, random_state):\n",
        "    \"\"\"\n",
        "    層化K分割したindexのリストを返す。\n",
        "    n_splits<=1 の場合、全indexを返す。\n",
        "    \"\"\"\n",
        "    if n_splits > 1:\n",
        "        skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
        "        return list(skf.split(train_df, train_df[Config.target_col]))\n",
        "    else:\n",
        "        return train.index\n",
        "\n",
        "\n",
        "def tokenize_texts(texts, tokenizer):\n",
        "    \"\"\"\n",
        "    バッチ化された文字列をtoken化し、\n",
        "    keyが\"input_ids\"と\"attention_mask\"の辞書として返す。\n",
        "    \"\"\"\n",
        "    tokenized_dict = tokenizer.batch_encode_plus(\n",
        "        texts,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=Config.max_length,\n",
        "        return_token_type_ids=False,\n",
        "    )\n",
        "    return dict(tokenized_dict)\n",
        "\n",
        "\n",
        "def get_dataset(x, y=None, dataset=\"test\"):\n",
        "    \"\"\"\n",
        "    データをtf.data.Datasetの形式に変換する。\n",
        "    \"\"\"\n",
        "    if dataset==\"train\":\n",
        "        tr_ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        if Config.steps_per_epochs is not None:\n",
        "            tr_ds = tr_ds.repeat()\n",
        "        tr_ds = tr_ds.shuffle(2048)\n",
        "        tr_ds = tr_ds.batch(Config.train_batch_size)\n",
        "        tr_ds = tr_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return tr_ds\n",
        "\n",
        "    elif dataset==\"valid\":\n",
        "        val_ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        val_ds = val_ds.batch(Config.valid_batch_size)\n",
        "        val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return val_ds\n",
        "    \n",
        "    elif dataset==\"test\":\n",
        "        test_ds = tf.data.Dataset.from_tensor_slices(x)\n",
        "        test_ds = test_ds.batch(Config.test_batch_size)\n",
        "        test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return test_ds"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdAYKZGQaEjq"
      },
      "source": [
        "# ６. 訓練準備\n",
        "model訓練時に必要な関数を定義します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Bd-ENfaRef"
      },
      "source": [
        "## 6.1 カスタム損失関数\n",
        "自作の損失関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6AmkOBbSyfC"
      },
      "source": [
        "def weighted_binary_crossentropy(weight, label_smoothing):\n",
        "    \"\"\"\n",
        "    負例、正例にそれぞれ異なる重み付けをするcrossentropy損失関数\n",
        "    \"\"\"\n",
        "    weight = tf.convert_to_tensor(weight, dtype=tf.float32)\n",
        "\n",
        "    def _weighted_binary_crossentropy(target, output):\n",
        "        \"\"\"\n",
        "        label smoothingに対応した一般的なcrossentropy損失関数\n",
        "        keras公式の実装を参考に実装\n",
        "\n",
        "        \"\"\"\n",
        "        if Config.label_smoothing:\n",
        "            target = target * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "        target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "        target = tf.reshape(target, [-1])\n",
        "\n",
        "        output = tf.convert_to_tensor(output, dtype=tf.float32)\n",
        "        output = tf.reshape(output, [-1])\n",
        "        epsilon_ = K.epsilon()\n",
        "        output = tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
        "\n",
        "        bce = weight[1] * target * tf.math.log(output + K.epsilon())\n",
        "        bce += weight[0] * (1 - target) * tf.math.log(1 - output + K.epsilon())\n",
        "        return -bce\n",
        "\n",
        "    return _weighted_binary_crossentropy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZfk8-Abj2b"
      },
      "source": [
        "## 6.2 閾値最適化アルゴリズム\n",
        "閾値の最適化に必要な関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtGblpDAbkUR"
      },
      "source": [
        "def opt_fbeta_threshold(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    閾値のfbeta score最適化アルゴリズム\n",
        "    \"\"\"\n",
        "    def opt_(x): \n",
        "        return -fbeta_score(y_true, y_pred>=x, beta=7)\n",
        "    if Config.opt == \"minimize\":\n",
        "        result = minimize(opt_, x0=np.array([0.1]), method=\"Powell\")\n",
        "    elif Config.opt == \"minimize_scalar\":\n",
        "        result = minimize_scalar(opt_, bounds=(0.001, 0.85), method='bounded')\n",
        "    opted_threshold = result['x'].item()\n",
        "    return opted_threshold"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2pMn0fDiXSX"
      },
      "source": [
        "## 6.3 訓練結果\n",
        "訓練結果を取得したり表示する為の関数です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cBPoNKgEJ_k"
      },
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    最適化された閾値とその時のfbeta scoreを取得する。\n",
        "    \"\"\"\n",
        "    opted_thre = opt_fbeta_threshold(y_true, y_pred)\n",
        "    print(f\"opted threshold : {opted_thre}\")\n",
        "    score = fbeta_score(y_true, y_pred >= opted_thre, beta=7)\n",
        "    return score, opted_thre\n",
        "\n",
        "\n",
        "def get_result(y_true, y_pred, thresholds=None):\n",
        "    \"\"\"\n",
        "    様々な閾値とその時のfbetaスコアをpd.DataFrameとして返す。\n",
        "\n",
        "    1.　閾値のlistが与えられなかった場合\n",
        "    仮の閾値(Config.temp_thre)、最適化した閾値と\n",
        "    それらに対応するfbetaスコアを計算し、pd.DataFrameに格納する。\n",
        "\n",
        "    2.　閾値のlistが与えられた場合\n",
        "    その最大値、最小値、平均値、中央値と\n",
        "    それらに対応するfbetaスコアを計算し、上に追加する。\n",
        "    \"\"\"\n",
        "    thre_df = pd.DataFrame(columns=[\"threshold\", \"score\"])\n",
        "\n",
        "    naive_score = fbeta_score(y_true, y_pred >= Config.temp_thre, beta=6.0)\n",
        "    opted_score, opted_thre = metrics(y_true, y_pred)\n",
        "    type_list = [\"opted\", \"temporary\"]\n",
        "    thre_list = [opted_thre, Config.temp_thre]\n",
        "    score_list = [opted_score, naive_score]\n",
        "\n",
        "    if type(thresholds) is list:\n",
        "        thresholds = np.array(thresholds)\n",
        "        min_thre = thresholds.min()\n",
        "        max_thre = thresholds.max()\n",
        "        mean_thre = thresholds.mean()\n",
        "        med_thre = np.median(thresholds)\n",
        "\n",
        "        min_score = fbeta_score(y_true, y_pred >= min_thre, beta=6.0)\n",
        "        max_score = fbeta_score(y_true, y_pred >= max_thre, beta=6.0)\n",
        "        mean_score = fbeta_score(y_true, y_pred >= mean_thre, beta=6.0)\n",
        "        med_score = fbeta_score(y_true, y_pred >= med_thre, beta=6.0)\n",
        "\n",
        "        type_list += [\"min\", \"max\", \"mean\",\"median\"]\n",
        "        thre_list += [min_thre, max_thre, mean_thre, med_thre]\n",
        "        score_list += [min_score, max_score, mean_score, med_score] \n",
        "\n",
        "    thre_df[\"threshold\"] = thre_list\n",
        "    thre_df[\"score\"] = score_list\n",
        "    thre_df.index = type_list\n",
        "    return thre_df\n",
        "\n",
        "\n",
        "def visualize_confusion_matrix(\n",
        "        y_true,\n",
        "        pred_label,\n",
        "        height=.6,\n",
        "        labels=None):\n",
        "    \"\"\"\n",
        "    混合行列を表示する。\n",
        "    \"\"\"\n",
        "    conf = confusion_matrix(y_true=y_true,\n",
        "                            y_pred=pred_label,\n",
        "                            normalize='true')\n",
        "\n",
        "    n_labels = len(conf)\n",
        "    size = n_labels * height\n",
        "    fig, ax = plt.subplots(figsize=(size * 4, size * 3))\n",
        "    sns.heatmap(conf, cmap='Blues', ax=ax, annot=True, fmt='.2f')\n",
        "    ax.set_ylabel('Label')\n",
        "    ax.set_xlabel('Predict')\n",
        "\n",
        "    if labels is not None:\n",
        "        ax.set_yticklabels(labels)\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.tick_params('y', labelrotation=0)\n",
        "        ax.tick_params('x', labelrotation=90)\n",
        "\n",
        "    plt.show()\n",
        "    return fig"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSmt_CdkcD4I"
      },
      "source": [
        "## 6.4 class weight\n",
        "model.fit()の引数：class_weightに渡す値を取得します。<br>\n",
        "model.fit()は、学習時にはclass_weightに従ってlossに重みを乗算しますが、<br>\n",
        "検証データ評価時には、適用しないので、指標のval_lossは重みが乗算された値となりません。<br>\n",
        "故に、もしval_lossにも重み付けをする場合、損失関数は前述のweighted_binary_crossentropyを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXTkZh1_Gv9n"
      },
      "source": [
        "def get_class_weight(target, weight):\n",
        "    \"\"\"\n",
        "    class weightを取得する。\n",
        "    \"\"\"\n",
        "    if weight == \"balanced\":\n",
        "        class_weights = class_weight.compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.unique(target),\n",
        "            y=target)\n",
        "        class_weights = dict(enumerate(class_weights))\n",
        "    elif weight is None:\n",
        "        class_weights = None\n",
        "    else:\n",
        "        # ex) weight = {0:0.2, 1:0.98}\n",
        "        class_weights = weight\n",
        "    \n",
        "    return class_weights"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I-hS_nrqeRy"
      },
      "source": [
        "## 6.5 訓練関数、推論関数\n",
        "訓練、推論部分の手順を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brnebJMGtIds"
      },
      "source": [
        "def train_fn(train_df, valid_df, model, tokenizer, filepath):\n",
        "    \"\"\"\n",
        "    訓練関数\n",
        "    \"\"\"\n",
        "    # tf.data.Dataset準備\n",
        "    tr_text = tokenize_texts(texts=train_df[Config.text_col].tolist(), \n",
        "                             tokenizer=tokenizer)\n",
        "    val_text = tokenize_texts(texts=valid_df[Config.text_col].tolist(),\n",
        "                              tokenizer=tokenizer)\n",
        "\n",
        "    tr_ds = get_dataset(x=tr_text, \n",
        "                        y=train_df[Config.target_col].values, \n",
        "                        dataset=\"train\")\n",
        "    val_ds = get_dataset(x=val_text, \n",
        "                         y=valid_df[Config.target_col].values, \n",
        "                         dataset=\"valid\")\n",
        "\n",
        "    # callbacks\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath, \n",
        "        monitor=Config.check_monitor, \n",
        "        verbose=1, \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True,\n",
        "        mode=Config.check_mode\n",
        "        )\n",
        "    \n",
        "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=Config.patience\n",
        "        )\n",
        "    \n",
        "    # 訓練実行\n",
        "    history = model.fit(\n",
        "        tr_ds, \n",
        "        epochs=Config.epochs, \n",
        "        verbose=1, \n",
        "        callbacks=[checkpoint, earlystop],\n",
        "        validation_data=val_ds, \n",
        "        steps_per_epoch=Config.steps_per_epochs,\n",
        "        class_weight=get_class_weight(train_df[Config.target_col], \n",
        "                                      weight=Config.class_weight)\n",
        "        )\n",
        "    \n",
        "    return history\n",
        "\n",
        "\n",
        "def inference_fn(test_df, model, tokenizer, filepath):\n",
        "    \"\"\"\n",
        "    推論関数\n",
        "    \"\"\"\n",
        "    model.load_weights(filepath)\n",
        "    te_text = tokenize_texts(texts=test_df[Config.text_col].tolist(), \n",
        "                             tokenizer=tokenizer)\n",
        "    te_ds = get_dataset(x=te_text, y=None, dataset=\"test\")\n",
        "    preds = model.predict(te_ds)\n",
        "    return preds.reshape(-1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96mVy8p7tWek"
      },
      "source": [
        "## 6.6 交差検証関数\n",
        "cross validationの手順を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC8gn_UgtVZU"
      },
      "source": [
        "def train_cv(train_df, kf, metrics, name, dir):\n",
        "    \"\"\"\n",
        "    cross validationの実行関数 (train)\n",
        "    \"\"\"\n",
        "    # oofの予測確率(probability)と最適化された閾値の保存領域\n",
        "    oof_preds = np.zeros(len(train_df))\n",
        "    threshold_list = []\n",
        "\n",
        "    # k分割訓練\n",
        "    for i_fold, (tr_idx, val_idx) in enumerate(kf):\n",
        "        K.clear_session()\n",
        "        print(f\"\\n===== FOLD {i_fold+1} training =====\")\n",
        "        filepath = os.path.join(dir, f\"{name}_fold{i_fold+1}.h5\")\n",
        "\n",
        "        # model, tokenizerの準備\n",
        "        model = get_model()\n",
        "        tokenizer = transformers.AutoTokenizer.from_pretrained(Config.model)\n",
        "\n",
        "        # dataの分割\n",
        "        tr_df = train_df.iloc[tr_idx].reset_index()\n",
        "        val_df = train_df.iloc[val_idx].reset_index()\n",
        "        \n",
        "        # 学習済みモデルがあれば訓練しない\n",
        "        if not os.path.isfile(filepath):\n",
        "            history = train_fn(tr_df, val_df, model, tokenizer, filepath)\n",
        "            pd.DataFrame(history.history).to_csv(\n",
        "                os.path.join(LOG, f\"history{time_jp}_{i_fold+1}.csv\"), \n",
        "                index=False)\n",
        "\n",
        "        # oofの予測確率を計算し、\n",
        "        # 最適化された閾値とスコアをpd.DataFrameとして取得\n",
        "        preds = inference_fn(val_df, model, tokenizer, filepath)\n",
        "        thre_df = get_result(val_df[Config.target_col], preds)\n",
        "\n",
        "        # 最適化された閾値\n",
        "        opted_thre = thre_df[thre_df.index==\"opted\"].threshold.values[0]\n",
        "\n",
        "        logger.info(f\"===== fold {i_fold+1} result =====\")\n",
        "        logger.info(f\">>> {thre_df.to_dict()}\")\n",
        "\n",
        "        # oofの予測確率値と最適化された閾値を保存\n",
        "        oof_preds[val_idx] = preds\n",
        "        threshold_list.append(opted_thre)\n",
        "    \n",
        "    # oof全体の最適な閾値と、threshold_listから得た閾値でスコアを計算\n",
        "    thre_df = get_result(train_df[Config.target_col], oof_preds, threshold_list)\n",
        "    logger.info(f\"===== total result =====\")\n",
        "    logger.info(f\">>> threshold:{thre_df.to_dict()['threshold']}\")\n",
        "    logger.info(f\">>> score:{thre_df.to_dict()['score']}\")\n",
        "    return oof_preds, threshold_list\n",
        "\n",
        "\n",
        "def predict_cv(test_df, name):\n",
        "    \"\"\"\n",
        "    cross validationの実行関数 (test)\n",
        "    fold毎に保存したそれぞれのモデルでtestファイルに対し\n",
        "    probabilityを予測し、平均する\n",
        "    \"\"\"\n",
        "    preds_fold = []\n",
        "    for i_fold in range(Config.n_fold):\n",
        "        filepath = os.path.join(MODEL, f\"{name}_fold{i_fold+1}.h5\")\n",
        "        model = get_model()\n",
        "        tokenizer = transformers.AutoTokenizer.from_pretrained(Config.model)\n",
        "\n",
        "        preds = inference_fn(test_df, model, tokenizer, filepath)\n",
        "        preds_fold.append(preds)\n",
        "\n",
        "        logger.info(f\"===== fold{i_fold+1} inference =====\")\n",
        "    \n",
        "    preds = np.mean(preds_fold, axis=0)\n",
        "    return preds"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESLDR_wftqr1"
      },
      "source": [
        "# ７. 提出準備\n",
        "交差検証訓練の結果得た様々な閾値で、提出ファイルを作成する関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MLt675RpWqS"
      },
      "source": [
        "def submit_with_thresholds(type_list, threshold_list):\n",
        "    \"\"\"\n",
        "    様々な閾値を用いて、submitファイルを作成、保存\n",
        "    \"\"\"\n",
        "    name = f\"{Config.model.replace('/','-')}_{time_jp}\"\n",
        "    # testファイルに対して予測したprobability\n",
        "    prob_df = pd.read_csv(os.path.join(PROB, f\"prob_{name}.csv\"))\n",
        "    # submitファイルの雛形\n",
        "    submit_df = pd.read_csv(os.path.join(INPUT, \"sample_submit.csv\"), \n",
        "                            header=None, \n",
        "                            names=[\"id\", \"judgement\"])\n",
        "    if Config.debug:\n",
        "        submit_df = submit_df.iloc[get_data(Config.test_file).index.values]\n",
        "        \n",
        "    # submit\n",
        "    for key, threshold in zip(type_list, threshold_list):\n",
        "        predictions = (prob_df[f\"{name}_seed{Config.seeds[0]}\"].values >= threshold) * 1\n",
        "        filepath = f\"{name}_{key}.csv\"\n",
        "        submit_df[\"judgement\"] = predictions\n",
        "        submit_df.to_csv(os.path.join(SUBMIT, filepath), \n",
        "                         index=False, \n",
        "                         header=False)\n",
        "        logger.info(f\"saved file : {name}_{key}.csv\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdFJ4htCK-lx"
      },
      "source": [
        "# ８. 実行\n",
        "全体の手順を定義し、実行します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUI_ZPr6S2p3"
      },
      "source": [
        "def main():\n",
        "    # 訓練ごとに異なるファイル名を作成\n",
        "    model_name = f\"{Config.model.replace('/','-')}_{time_jp}\"\n",
        "    logger.info(f\"{model_name} TRAINING\")\n",
        "\n",
        "    # data準備\n",
        "    train_df = get_data(Config.train_file)\n",
        "    test_df = get_data(Config.test_file)\n",
        "\n",
        "    # 設定したseeds毎に訓練\n",
        "    oof_df = pd.DataFrame()\n",
        "    threshold_list = []\n",
        "    for seed in Config.seeds:\n",
        "        name = f\"{model_name}_seed{seed}\"\n",
        "        logger.info(f\"***** SEED{seed} *****\")\n",
        "        oof_preds, seed_thre_list = train_cv(\n",
        "            train_df, \n",
        "            kf=skf(train_df, n_splits=Config.n_fold, random_state=seed),\n",
        "            metrics=metrics, \n",
        "            name=name, \n",
        "            dir=MODEL)\n",
        "        oof_df[name] = oof_preds\n",
        "        threshold_list += seed_thre_list\n",
        "\n",
        "    # oofの予測値(probability)を保存\n",
        "    oof_df.to_csv(os.path.join(PROB, f\"oof_{model_name}.csv\"), index=False)\n",
        "    logger.info(f\"saved file : oof_{model_name}.csv\")\n",
        "\n",
        "    # トータルスコアを記録\n",
        "    y_true = train_df[Config.target_col].values\n",
        "    y_pred = oof_df.mean(axis=1).values\n",
        "    thre_df = get_result(y_true, y_pred, threshold_list)\n",
        "    \n",
        "    logger.info(f\"***** seeds total result *****\")\n",
        "    logger.info(f\">>> threshold:{thre_df.to_dict()['threshold']}\")\n",
        "    logger.info(f\">>> score:{thre_df.to_dict()['score']}\")\n",
        "\n",
        "    # 最適閾値で混合行列を表示\n",
        "    opted_thre = thre_df[thre_df.index==\"opted\"].threshold.values[0]\n",
        "    fig = visualize_confusion_matrix(y_true, y_pred>=opted_thre)\n",
        "    fig.savefig(os.path.join(LOG, f\"cm_{time_jp}.png\"), dpi=300)\n",
        "\n",
        "    # test予測値(probability)を計算\n",
        "    preds_df = pd.DataFrame()\n",
        "    for seed in Config.seeds:\n",
        "        name = f\"{model_name}_seed{seed}\"\n",
        "        preds = predict_cv(test_df, name)\n",
        "        preds_df[name] = preds\n",
        "\n",
        "    # test予測値(probability)を保存\n",
        "    preds_df.to_csv(os.path.join(PROB, f\"prob_{model_name}.csv\"), index=False)  \n",
        "    logger.info(f\"saved file : prob_{name}.csv\")\n",
        "\n",
        "    # submit\n",
        "    if Config.submit:\n",
        "        submit_with_thresholds(thre_df.index, thre_df.threshold)\n",
        "\n",
        "    # ハイパーパラメーターとkeras.modelの構造を記録\n",
        "    code_text = \"\"\n",
        "    with open(os.path.join(DRIVE, \"medical_bert_tf.ipynb\"), mode=\"r\") as f:\n",
        "        code = f.read()\n",
        "\n",
        "    for i in [2,3]:\n",
        "        code_text += \"\".join(json.loads(code)[\"cells\"][i][\"source\"])+\"\\n\\n\"\n",
        "\n",
        "    logger.info(code_text)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51KXC98yt7CB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73b0353b-eab4-447d-821f-aa8c88537709"
      },
      "source": [
        "main()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:[2021-11-02 22:06:16] - dmis-lab-biobert-base-cased-v1.2_20211102_2135 TRAINING\n",
            "INFO:__main__:[2021-11-02 22:06:17] - ***** SEED21 *****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FOLD 1 training =====\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n",
            "INFO:__main__:[2021-11-02 22:07:58] - ===== fold 1 result =====\n",
            "INFO:__main__:[2021-11-02 22:07:58] - >>> {'threshold': {'opted': -1.4994280624162823, 'temporary': 0.1}, 'score': {'opted': 0.6702412868632708, 'temporary': 0.6006493506493507}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opted threshold : -1.4994280624162823\n",
            "\n",
            "===== FOLD 2 training =====\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n",
            "INFO:__main__:[2021-11-02 22:09:45] - ===== fold 2 result =====\n",
            "INFO:__main__:[2021-11-02 22:09:45] - >>> {'threshold': {'opted': 0.14460922713941426, 'temporary': 0.1}, 'score': {'opted': 0.7653061224489796, 'temporary': 0.6607142857142858}}\n",
            "INFO:__main__:[2021-11-02 22:09:45] - ===== total result =====\n",
            "INFO:__main__:[2021-11-02 22:09:45] - >>> threshold:{'opted': 0.14461537636747432, 'temporary': 0.1, 'min': -1.4994280624162823, 'max': 0.14460922713941426, 'mean': -0.677409417638434, 'median': -0.677409417638434}\n",
            "INFO:__main__:[2021-11-02 22:09:45] - >>> score:{'opted': 0.7208387942332897, 'temporary': 0.6319875776397516, 'min': 0.6242331288343558, 'max': 0.6564516129032257, 'mean': 0.6242331288343558, 'median': 0.6242331288343558}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opted threshold : 0.14460922713941426\n",
            "opted threshold : 0.14461537636747432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:[2021-11-02 22:09:45] - saved file : oof_dmis-lab-biobert-base-cased-v1.2_20211102_2135.csv\n",
            "INFO:__main__:[2021-11-02 22:09:45] - ***** seeds total result *****\n",
            "INFO:__main__:[2021-11-02 22:09:45] - >>> threshold:{'opted': 0.14461537636747432, 'temporary': 0.1, 'min': -1.4994280624162823, 'max': 0.14460922713941426, 'mean': -0.677409417638434, 'median': -0.677409417638434}\n",
            "INFO:__main__:[2021-11-02 22:09:45] - >>> score:{'opted': 0.7208387942332897, 'temporary': 0.6319875776397516, 'min': 0.6242331288343558, 'max': 0.6564516129032257, 'mean': 0.6242331288343558, 'median': 0.6242331288343558}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opted threshold : 0.14461537636747432\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 345.6x259.2 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3334fb00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3334fb00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "INFO:__main__:[2021-11-02 22:11:22] - ===== fold1 inference =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.38.49.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.49.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3344216f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3344216f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "INFO:__main__:[2021-11-02 22:13:47] - ===== fold2 inference =====\n",
            "INFO:__main__:[2021-11-02 22:13:47] - saved file : prob_dmis-lab-biobert-base-cased-v1.2_20211102_2135_seed21.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - saved file : dmis-lab-biobert-base-cased-v1.2_20211102_2135_opted.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - saved file : dmis-lab-biobert-base-cased-v1.2_20211102_2135_temporary.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - saved file : dmis-lab-biobert-base-cased-v1.2_20211102_2135_min.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - saved file : dmis-lab-biobert-base-cased-v1.2_20211102_2135_max.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - saved file : dmis-lab-biobert-base-cased-v1.2_20211102_2135_mean.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - saved file : dmis-lab-biobert-base-cased-v1.2_20211102_2135_median.csv\n",
            "INFO:__main__:[2021-11-02 22:13:48] - class Config:\n",
            "    model = \"dmis-lab/biobert-base-cased-v1.2\" #@param\n",
            "    from_pt = True #@param {\"type\":\"boolean\"}\n",
            "    encode_type = \"cls_cat\" #@param {\"type\",\"string\"} [\"cls\",\"cls_cat\",\"pooler\",\"logits\", \"last_hidden_state_cnn\", \"last_hidden_state_lstm\"]\n",
            "\n",
            "    max_length = 512 #@param {\"type\":\"integer\"}\n",
            "    lr = 0.00002\n",
            "    weight_decay = 1e-5\n",
            "    opt = \"minimize\"  #@param {\"type\":\"string\"} [\"minimize_scalar\",\"minimize\"]\n",
            "    n_fold = 5 #@param\n",
            "    epochs = 15 #@param {\"type\":\"slider\"}\n",
            "    patience =  4#@param\n",
            "    check_monitor = \"val_fbeta_score\" #@param {\"type\":\"string\"} [\"val_loss\",\"val_fbeta_score\",\"val_auc\"]\n",
            "    check_mode = \"max\" #@param {\"type\":\"string\"} [\"auto\", \"max\"]\n",
            "    \n",
            "    train_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
            "    valid_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
            "    test_batch_size = 64 #@param {\"type\":\"raw\"} [4,8,16,32,64]\n",
            "    steps_per_epochs = None #(27145 * (n_fold - 1) / n_fold) // train_batch_size\n",
            "    train_file = \"ps_train.csv\" #@param\n",
            "    test_file = \"ps_test.csv\" #@param\n",
            "    target_col = \"judgement\"\n",
            "    text_col = \"summary\"  #@param {\"type\":\"string\"} [\"text\",\"summary\"]\n",
            "    seeds = [21]\n",
            "\n",
            "    loss_fn = \"bce\" #@param {\"type\":\"string\"} [\"bce\", \"weighted_bce\", \"focal\"]\n",
            "    loss_weight = [1,50] #@param\n",
            "    class_weight = \"balanced\" #@param {\"type\":\"raw\"} \n",
            "    sample_weight = None #@param    \n",
            "    label_smoothing = 0 #@param\n",
            "    \n",
            "    submit = True #@param {\"type\":\"boolean\"}\n",
            "    debug = False  #@param {\"type\":\"boolean\"}\n",
            "    temp_thre = 0.1 #@param\n",
            "\n",
            "if Config.debug:\n",
            "    Config.epochs = 2\n",
            "    Config.n_fold = 2\n",
            "\n",
            "time_jp = (datetime.datetime.now() + \n",
            "           datetime.timedelta(hours=9)).strftime('%Y%m%d_%H%M')\n",
            "# time_jp = '20210926_1749' #@param\n",
            "time_jp\n",
            "\n",
            "def build_auto_model():\n",
            "    \n",
            "    # encoder\n",
            "    if Config.encode_type == \"logits\":\n",
            "        encoder = (\n",
            "            transformers\n",
            "            .TFAutoModelForSequenceClassification\n",
            "            .from_pretrained(Config.model, num_labels=1, from_pt=Config.from_pt)\n",
            "        )\n",
            "    elif Config.encode_type == \"cls_cat\":\n",
            "        config = transformers.AutoConfig.from_pretrained(Config.model,\n",
            "                                                         output_hidden_states=True)\n",
            "        encoder = (\n",
            "            transformers\n",
            "            .TFAutoModel\n",
            "            .from_pretrained(Config.model, config=config, from_pt=Config.from_pt)\n",
            "        )\n",
            "\n",
            "    else:\n",
            "        encoder = (\n",
            "            transformers\n",
            "            .TFAutoModel\n",
            "            .from_pretrained(Config.model, from_pt=Config.from_pt)\n",
            "        )\n",
            "    \n",
            "    input_word_ids = tf.keras.layers.Input(shape=(Config.max_length, ), dtype=tf.int32, name='input_ids')\n",
            "    attention_mask = tf.keras.layers.Input(shape=(Config.max_length, ), dtype=tf.int32, name='attention_mask')\n",
            "    x = encoder(input_word_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
            "\n",
            "    # output token type\n",
            "    if Config.encode_type == \"cls\":\n",
            "        x = x[0][:, 0, :]  # cls token\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "\n",
            "    elif Config.encode_type == \"cls_cat\":\n",
            "        x = tf.concat([x[\"hidden_states\"][-i][:,0,:] for i in range(1,5)], axis=-1)\n",
            "        x = tf.keras.layers.Dropout(0.2)(x)\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "\n",
            "    elif Config.encode_type == \"pooler\":\n",
            "        x = x[\"pooler_output\"]\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "\n",
            "    elif Config.encode_type == \"logits\":\n",
            "        x = x.logits\n",
            "        output = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
            "\n",
            "    elif Config.encode_type == \"last_hidden_state_cnn\":\n",
            "        x = x.last_hidden_state\n",
            "        x = tf.keras.layers.Conv1D(\n",
            "            256, kernel_size=2, padding=\"same\", activation=\"relu\")(x)\n",
            "        x = tf.keras.layers.Conv1D(\n",
            "            1, kernel_size=2, padding=\"same\")(x)\n",
            "        x = tf.keras.layers.GlobalMaxpooling1D()(x)\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "        \n",
            "    elif Config.encode_type == \"last_hidden_state_lstm\":\n",
            "        x = x.last_hidden_state\n",
            "        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(728))(x)\n",
            "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
            "        \n",
            "\n",
            "    model = tf.keras.models.Model(inputs=[input_word_ids, attention_mask],\n",
            "                                  outputs=[output])\n",
            "\n",
            "    optimizer = tfa.optimizers.AdamW(lr=Config.lr, weight_decay=Config.weight_decay)\n",
            "\n",
            "    loss = {\"bce\": tf.keras.losses.BinaryCrossentropy(),\n",
            "            \"weighted_bce\": weighted_binary_crossentropy(Config.loss_weight, Config.label_smoothing),\n",
            "            \"focal\": tfa.losses.SigmoidFocalCrossEntropy(alpha=0.98, gamma=2.0),\n",
            "            \"mse\": tf.keras.losses.MeanSquaredError()}\n",
            "\n",
            "    metrics = [tfa.metrics.FBetaScore(num_classes=1,\n",
            "                                      beta=7.0,\n",
            "                                      threshold=Config.temp_thre),\n",
            "               tf.keras.metrics.AUC(num_thresholds=200, curve='PR',\n",
            "                                    multi_label=False, label_weights=None)]\n",
            "\n",
            "    model.compile(optimizer=optimizer,\n",
            "                  loss=loss[Config.loss_fn], \n",
            "                  metrics=metrics)\n",
            "    # model.summary()\n",
            "    return model\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}